{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TOrZeq6djW6",
        "outputId": "f3c94573-1c28-4300-8348-f0209b4c1032"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vku7FYbEdoCN",
        "outputId": "f2f86fd7-df3b-4572-aca9-290ced9e1d9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.8/68.8 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pybind11>=2.2 (from fasttext)\n",
            "  Using cached pybind11-2.11.1-py3-none-any.whl (227 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext) (67.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fasttext) (1.22.4)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp310-cp310-linux_x86_64.whl size=4199775 sha256=aeef8c577825d9d3629c39cfba717a476269bab4c9df1eb2ffd4367376b5021e\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/13/75/f811c84a8ab36eedbaef977a6a58a98990e8e0f1967f98f394\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.2 pybind11-2.11.1\n"
          ]
        }
      ],
      "source": [
        "!pip install fasttext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QEqW9E8sduPS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv('/content/drive/MyDrive/hate rate/task 4/dataset/train_AH_preprocessed.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming 'df' is your DataFrame\n",
        "df = df.sample(frac=1).reset_index(drop=True)\n"
      ],
      "metadata": {
        "id": "g4Pg1bAO5Jdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKFhXljEjqOY",
        "outputId": "0a68dfb5-1b0b-4752-d495-68911c8df77d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-5acdf9bf36d9>:2: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "  output=pd.Series()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "66\n"
          ]
        }
      ],
      "source": [
        "#convert label to int\n",
        "output=pd.Series()\n",
        "for indx,row in df.iterrows():\n",
        "  current=row['task_1']\n",
        "  if(current==\"NOT\"):\n",
        "    output.at[indx]=0\n",
        "  else:\n",
        "    output.at[indx]=1\n",
        "df['output']=output\n",
        "\n",
        "\n",
        "#finding longest sentence\n",
        "maxx=0\n",
        "\n",
        "for s in df['text']:\n",
        "  s_len=len(s.split())\n",
        "  if(s_len>maxx):\n",
        "    sent=s\n",
        "  maxx=max(s_len,maxx)\n",
        "\n",
        "\n",
        "print(maxx)\n",
        "# Pad sequences to a fixed length (adjust MAX_LEN if needed)\n",
        "MAX_LEN = maxx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFOTdtjId9Tt",
        "outputId": "73be3048-789d-486f-8951-84db13c676ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        }
      ],
      "source": [
        "import fasttext\n",
        "\n",
        "# Replace 'path_to_model.bin' with the actual path to your .bin file\n",
        "fasttext_model = fasttext.load_model('/content/drive/MyDrive/hate rate/task 4/fasttext/assamese/cc.as.300.bin')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96NGmaR8frBi"
      },
      "source": [
        "i think i dont need word_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0IjU_MzveD0j"
      },
      "outputs": [],
      "source": [
        "def load_word_vectors(file_path):\n",
        "    word_vectors = {}\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            values = line.rstrip().split(' ')\n",
        "            word = values[0]\n",
        "            vector = [float(val) for val in values[1:]]\n",
        "            word_vectors[word] = vector\n",
        "    return word_vectors\n",
        "\n",
        "# Replace 'path_to_vectors.vec' with the actual path to your .vec file\n",
        "word_vectors = load_word_vectors('/content/drive/MyDrive/hate rate/task 4/fasttext/assamese/cc.as.300.vec')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNWQx0v7eEmF",
        "outputId": "b0324671-f6a3-455f-c2ca-49fbe4013dce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of words in fasttext of our tokenizer are :  6786\n"
          ]
        }
      ],
      "source": [
        "import fasttext\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Load your FastText model\n",
        "#TODO add filters=' ' to tokenizer\n",
        "# Create a tokenizer based on FastText vocabulary\n",
        "tokenizer = Tokenizer(oov_token='<oov>')\n",
        "tokenizer.fit_on_texts(df['text'].tolist())\n",
        "# Add special tokens to the tokenizer\n",
        "\n",
        "# Convert sentences to sequences of word indices\n",
        "sequences = tokenizer.texts_to_sequences(df['text'].tolist())\n",
        "\n",
        "# Pad sequences to a uniform length\n",
        "max_sequence_length = 180  # Define your desired sequence length\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length, padding='post', truncating='post')\n",
        "\n",
        "# Create the embedding matrix\n",
        "embedding_dim = 300  # Adjust based on your FastText embeddings\n",
        "num_words = len(tokenizer.word_index) + 1  # Add 1 for the padding token\n",
        "count_yes=0\n",
        "embedding_matrix = np.zeros((num_words, embedding_dim))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if word in fasttext_model:\n",
        "        count_yes+=1\n",
        "        embedding_matrix[i] = fasttext_model[word]\n",
        "    else:\n",
        "        # Initialize random embedding for OOV words\n",
        "        embedding_matrix[i] = np.random.uniform(-1, 1, embedding_dim)\n",
        "# Now you can use 'embedding_matrix' as the 'weights' parameter when creating the Embedding layer in your model\n",
        "print('number of words in fasttext of our tokenizer are : ',count_yes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPC55Cq6f6m2",
        "outputId": "7fbe3878-27e3-47b1-b1ab-636f7e64b082"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11173"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "len(tokenizer.word_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lUH4WanmSzk",
        "outputId": "ff765296-8523-4928-d91b-7848aa438f58"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11174, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "embedding_matrix.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wgtzs-Xln-l3"
      },
      "outputs": [],
      "source": [
        "train_input=padded_sequences\n",
        "train_output=np.array(df['output'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7DWA8vOJinKA"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "#train_df, val_df = train_test_split(df, test_size=0.1, random_state=42)\n",
        "\n",
        "# Convert the DataFrame to a TensorFlow dataset\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_input, train_output))\n",
        "##val_dataset = tf.data.Dataset.from_tensor_slices((val_df['seq'], val_df['output']))\n",
        "\n",
        "# Shuffle and batch the datasets\n",
        "batch_size = 32\n",
        "train_dataset = train_dataset.shuffle(len(df)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "#val_dataset = val_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PfSEyPgkXk_",
        "outputId": "9065d168-dc46-43e5-fedd-2ca3e485fddf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 180)]        0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 180, 300)     3352200     ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)                (None, 149, 128)     1228928     ['embedding[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_1 (Conv1D)              (None, 149, 128)     1228928     ['embedding[0][0]']              \n",
            "                                                                                                  \n",
            " max_pooling1d (MaxPooling1D)   (None, 74, 128)      0           ['conv1d[0][0]']                 \n",
            "                                                                                                  \n",
            " max_pooling1d_1 (MaxPooling1D)  (None, 74, 128)     0           ['conv1d_1[0][0]']               \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 74, 256)      0           ['max_pooling1d[0][0]',          \n",
            "                                                                  'max_pooling1d_1[0][0]']        \n",
            "                                                                                                  \n",
            " bidirectional (Bidirectional)  (None, 128)          164352      ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 64)           8256        ['bidirectional[0][0]']          \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 64)           0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 32)           2080        ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 1)            33          ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 5,984,777\n",
            "Trainable params: 5,984,777\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, LSTM, Dense, Add, Input,Concatenate,Bidirectional,Dropout\n",
        "\n",
        "# Assuming you have loaded FastText embeddings into 'embedding_matrix'\n",
        "\n",
        "# Input layer\n",
        "input_layer = Input(shape=(max_sequence_length,))\n",
        "\n",
        "# Embedding layer\n",
        "embedding_layer = Embedding(input_dim=num_words,\n",
        "                            output_dim=embedding_dim,\n",
        "                            weights=[embedding_matrix],\n",
        "                            input_length=max_sequence_length,\n",
        "                            trainable=True)(input_layer)\n",
        "\n",
        "# 1D CNN layer with MaxPooling\n",
        "# Convolutional layers with different filter lengths\n",
        "conv4 = Conv1D(filters=128, kernel_size=32, activation='relu')(embedding_layer)\n",
        "maxConv4 = MaxPooling1D(pool_size=2)(conv4)\n",
        "\n",
        "conv5 = Conv1D(filters=128, kernel_size=32, activation='relu')(embedding_layer)\n",
        "maxConv5 = MaxPooling1D(pool_size=2)(conv5)\n",
        "\n",
        "# Concatenate the outputs of the Convolutional layers\n",
        "residual_connection = Concatenate(axis=-1)([maxConv4, maxConv5])\n",
        "\n",
        "# LSTM layer\n",
        "lstm_layer = Bidirectional(LSTM(64))(residual_connection)\n",
        "\n",
        "# Dense layer\n",
        "dense_layer = Dense(64, activation='relu')(lstm_layer)\n",
        "dense_layer=Dropout(0.5)(dense_layer)\n",
        "dense_layer = Dense(32, activation='relu')(dense_layer)\n",
        "# Output layer\n",
        "output_layer = Dense(1, activation='sigmoid')(dense_layer)\n",
        "\n",
        "# Create the model\n",
        "model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_val, y_train, y_val = train_test_split(train_input, train_output, test_size=0.1, random_state=22)"
      ],
      "metadata": {
        "id": "f-5vMBCt97NP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "BATCH_SIZE=8\n",
        "EPOCHS=1200\n",
        "\n",
        "\n",
        "  # You can adjust this value\n",
        "learning_rate = 0.000001\n",
        "momentum = 0.9  # Optional: If you want to use momentum\n",
        "\n",
        "# Create the SGD optimizer\n",
        "sgd_optimizer = SGD(learning_rate=learning_rate, momentum=momentum)\n",
        "ad= Adam(learning_rate=learning_rate)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer=ad, metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.fit(x_train,\n",
        "          y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          validation_data=(x_val,y_val),\n",
        "          epochs=EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-xuoUd5moFh",
        "outputId": "3c3d7230-1766-48b2-f90b-70bac2436297"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1200\n",
            "454/454 [==============================] - 46s 55ms/step - loss: 0.6935 - accuracy: 0.5052 - val_loss: 0.6937 - val_accuracy: 0.5025\n",
            "Epoch 2/1200\n",
            "454/454 [==============================] - 9s 20ms/step - loss: 0.6935 - accuracy: 0.4937 - val_loss: 0.6932 - val_accuracy: 0.5173\n",
            "Epoch 3/1200\n",
            "454/454 [==============================] - 9s 20ms/step - loss: 0.6927 - accuracy: 0.5374 - val_loss: 0.6928 - val_accuracy: 0.5272\n",
            "Epoch 4/1200\n",
            "454/454 [==============================] - 8s 19ms/step - loss: 0.6921 - accuracy: 0.5476 - val_loss: 0.6924 - val_accuracy: 0.5495\n",
            "Epoch 5/1200\n",
            "454/454 [==============================] - 7s 16ms/step - loss: 0.6920 - accuracy: 0.5471 - val_loss: 0.6920 - val_accuracy: 0.5693\n",
            "Epoch 6/1200\n",
            "454/454 [==============================] - 9s 19ms/step - loss: 0.6912 - accuracy: 0.5639 - val_loss: 0.6916 - val_accuracy: 0.5842\n",
            "Epoch 7/1200\n",
            "454/454 [==============================] - 8s 17ms/step - loss: 0.6909 - accuracy: 0.5699 - val_loss: 0.6912 - val_accuracy: 0.5842\n",
            "Epoch 8/1200\n",
            "454/454 [==============================] - 8s 18ms/step - loss: 0.6903 - accuracy: 0.5826 - val_loss: 0.6908 - val_accuracy: 0.5866\n",
            "Epoch 9/1200\n",
            "454/454 [==============================] - 8s 18ms/step - loss: 0.6896 - accuracy: 0.5815 - val_loss: 0.6903 - val_accuracy: 0.5866\n",
            "Epoch 10/1200\n",
            "454/454 [==============================] - 8s 17ms/step - loss: 0.6893 - accuracy: 0.5779 - val_loss: 0.6898 - val_accuracy: 0.5842\n",
            "Epoch 11/1200\n",
            "454/454 [==============================] - 9s 19ms/step - loss: 0.6885 - accuracy: 0.5804 - val_loss: 0.6893 - val_accuracy: 0.5866\n",
            "Epoch 12/1200\n",
            "454/454 [==============================] - 8s 17ms/step - loss: 0.6880 - accuracy: 0.5862 - val_loss: 0.6889 - val_accuracy: 0.5866\n",
            "Epoch 13/1200\n",
            "352/454 [======================>.......] - ETA: 1s - loss: 0.6868 - accuracy: 0.5877"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "after 60 epoch there was a chnage in val accuracy from 60.40 to 60.64% i am testing for 60 more epochs\n"
      ],
      "metadata": {
        "id": "LgrNLU4CHtf4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r_num=99\n",
        "x_train1, x_val1, y_train1, y_val1 = train_test_split(train_input, train_output, test_size=0.3, random_state=r_num)"
      ],
      "metadata": {
        "id": "EjL8QsmcAK7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x_val,y_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qY3rHHc564un",
        "outputId": "dc05de5d-cdb3-472e-8f6a-3ffe35038825"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "38/38 [==============================] - 0s 10ms/step - loss: 0.7655 - accuracy: 0.6210\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7655049562454224, 0.6209744215011597]"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#without early stopping we are getting 62%"
      ],
      "metadata": {
        "id": "MMShUBMOECug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "binar_class=np.where(output>0.5,1,0)"
      ],
      "metadata": {
        "id": "F2dT0zsF7JI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "63% with 30% data trained fresh\n"
      ],
      "metadata": {
        "id": "QqZLkIqp3N4d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## adding early stopping\n"
      ],
      "metadata": {
        "id": "f8UhJLaWCDyH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "BATCH_SIZE = 8\n",
        "EPOCHS = 30\n",
        "\n",
        "learning_rate = 0.00001\n",
        "momentum = 0.9\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "x_train, x_val, y_train, y_val = train_test_split(train_input, train_output, test_size=0.3, random_state=42)\n",
        "\n",
        "ad= Adam(learning_rate=learning_rate)\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer=ad, metrics=['accuracy'])\n",
        "\n",
        "# Define the EarlyStopping callback\n",
        "# Define the EarlyStopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', mode='max', patience=6, restore_best_weights=True)\n",
        "\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(x_train,\n",
        "                    y_train,\n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    validation_data=(x_val, y_val),\n",
        "                    epochs=EPOCHS,\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mAlhIcfCJGm",
        "outputId": "24179629-5ef7-4e97-f294-056e814259c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "354/354 [==============================] - 26s 57ms/step - loss: 0.6917 - accuracy: 0.5221 - val_loss: 0.6881 - val_accuracy: 0.5739\n",
            "Epoch 2/30\n",
            "354/354 [==============================] - 8s 23ms/step - loss: 0.6837 - accuracy: 0.5851 - val_loss: 0.6829 - val_accuracy: 0.5747\n",
            "Epoch 3/30\n",
            "354/354 [==============================] - 8s 24ms/step - loss: 0.6752 - accuracy: 0.5865 - val_loss: 0.6798 - val_accuracy: 0.5747\n",
            "Epoch 4/30\n",
            "354/354 [==============================] - 8s 24ms/step - loss: 0.6657 - accuracy: 0.5880 - val_loss: 0.6784 - val_accuracy: 0.5747\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "now training the model on k fold"
      ],
      "metadata": {
        "id": "fVfrFtyZ6LpA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Assuming you have 'train_input' and 'train_output' data loaded\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 3\n",
        "K_FOLDS = 5  # Number of folds for cross-validation\n",
        "\n",
        "# Create the Adam optimizer\n",
        "learning_rate=0.00001\n",
        "optimizer = Adam(learning_rate=learning_rate)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "# Initialize k-fold cross-validation\n",
        "kf = KFold(n_splits=K_FOLDS, shuffle=True, random_state=42)\n",
        "\n",
        "fold = 1\n",
        "for train_index, val_index in kf.split(train_input):\n",
        "    print(f\"Fold {fold}/{K_FOLDS}\")\n",
        "\n",
        "    # Create a new model for each fold\n",
        "    print('**************************reintializing****************')\n",
        "    model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "    # Get the train and validation data for this fold\n",
        "    x_train, x_val = train_input[train_index], train_input[val_index]\n",
        "    y_train, y_val = train_output[train_index], train_output[val_index]\n",
        "    before_score=model.evaluate(x_val, y_val, verbose=0)\n",
        "    print('before training the current validation score is ',before_score)\n",
        "    # Train the model for this fold\n",
        "    model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=15, validation_data=(x_val, y_val))\n",
        "\n",
        "    # Evaluate the model on the validation set\n",
        "    scores = model.evaluate(x_val, y_val, verbose=0)\n",
        "    print(f\"Fold {fold} - Validation loss: {scores[0]}, Validation accuracy: {scores[1]}\")\n",
        "\n",
        "    fold += 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "j3QTWYYX3xHy",
        "outputId": "b9aa291e-db5e-4cc0-b47a-f87a42463a6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1/5\n",
            "**************************reintializing****************\n",
            "before training the current validation score is  [0.6940086483955383, 0.4653465449810028]\n",
            "Epoch 1/15\n",
            "101/101 [==============================] - 20s 137ms/step - loss: 0.6924 - accuracy: 0.5372 - val_loss: 0.6902 - val_accuracy: 0.5631\n",
            "Epoch 2/15\n",
            "101/101 [==============================] - 6s 53ms/step - loss: 0.6884 - accuracy: 0.5864 - val_loss: 0.6881 - val_accuracy: 0.5681\n",
            "Epoch 3/15\n",
            "101/101 [==============================] - 5s 47ms/step - loss: 0.6852 - accuracy: 0.5858 - val_loss: 0.6861 - val_accuracy: 0.5681\n",
            "Epoch 4/15\n",
            "101/101 [==============================] - 6s 62ms/step - loss: 0.6821 - accuracy: 0.5861 - val_loss: 0.6845 - val_accuracy: 0.5681\n",
            "Epoch 5/15\n",
            "101/101 [==============================] - 4s 42ms/step - loss: 0.6784 - accuracy: 0.5843 - val_loss: 0.6831 - val_accuracy: 0.5681\n",
            "Epoch 6/15\n",
            "101/101 [==============================] - 4s 37ms/step - loss: 0.6754 - accuracy: 0.5852 - val_loss: 0.6824 - val_accuracy: 0.5681\n",
            "Epoch 7/15\n",
            "101/101 [==============================] - 3s 34ms/step - loss: 0.6738 - accuracy: 0.5864 - val_loss: 0.6818 - val_accuracy: 0.5681\n",
            "Epoch 8/15\n",
            "101/101 [==============================] - 4s 35ms/step - loss: 0.6695 - accuracy: 0.5867 - val_loss: 0.6814 - val_accuracy: 0.5681\n",
            "Epoch 9/15\n",
            "101/101 [==============================] - 3s 33ms/step - loss: 0.6651 - accuracy: 0.5892 - val_loss: 0.6809 - val_accuracy: 0.5681\n",
            "Epoch 10/15\n",
            "101/101 [==============================] - 3s 30ms/step - loss: 0.6625 - accuracy: 0.5920 - val_loss: 0.6801 - val_accuracy: 0.5681\n",
            "Epoch 11/15\n",
            "101/101 [==============================] - 3s 32ms/step - loss: 0.6568 - accuracy: 0.5979 - val_loss: 0.6794 - val_accuracy: 0.5681\n",
            "Epoch 12/15\n",
            "101/101 [==============================] - 4s 39ms/step - loss: 0.6516 - accuracy: 0.6059 - val_loss: 0.6785 - val_accuracy: 0.5681\n",
            "Epoch 13/15\n",
            "101/101 [==============================] - 3s 32ms/step - loss: 0.6444 - accuracy: 0.6193 - val_loss: 0.6770 - val_accuracy: 0.5668\n",
            "Epoch 14/15\n",
            "101/101 [==============================] - 3s 31ms/step - loss: 0.6338 - accuracy: 0.6363 - val_loss: 0.6762 - val_accuracy: 0.5681\n",
            "Epoch 15/15\n",
            "101/101 [==============================] - 3s 30ms/step - loss: 0.6291 - accuracy: 0.6478 - val_loss: 0.6750 - val_accuracy: 0.5705\n",
            "Fold 1 - Validation loss: 0.6750006079673767, Validation accuracy: 0.5705445408821106\n",
            "Fold 2/5\n",
            "**************************reintializing****************\n",
            "before training the current validation score is  [0.6159952878952026, 0.6319702863693237]\n",
            "Epoch 1/15\n",
            "101/101 [==============================] - 5s 31ms/step - loss: 0.6281 - accuracy: 0.6473 - val_loss: 0.6106 - val_accuracy: 0.6332\n",
            "Epoch 2/15\n",
            "101/101 [==============================] - 3s 29ms/step - loss: 0.6199 - accuracy: 0.6547 - val_loss: 0.6052 - val_accuracy: 0.6543\n",
            "Epoch 3/15\n",
            "101/101 [==============================] - 3s 34ms/step - loss: 0.6059 - accuracy: 0.6912 - val_loss: 0.5991 - val_accuracy: 0.6456\n",
            "Epoch 4/15\n",
            "101/101 [==============================] - 3s 34ms/step - loss: 0.5911 - accuracy: 0.6965 - val_loss: 0.5919 - val_accuracy: 0.6753\n",
            "Epoch 5/15\n",
            "101/101 [==============================] - 3s 31ms/step - loss: 0.5762 - accuracy: 0.7169 - val_loss: 0.5855 - val_accuracy: 0.6729\n",
            "Epoch 6/15\n",
            "101/101 [==============================] - 3s 35ms/step - loss: 0.5574 - accuracy: 0.7392 - val_loss: 0.5764 - val_accuracy: 0.6964\n",
            "Epoch 7/15\n",
            "101/101 [==============================] - 3s 30ms/step - loss: 0.5396 - accuracy: 0.7491 - val_loss: 0.5716 - val_accuracy: 0.6766\n",
            "Epoch 8/15\n",
            "101/101 [==============================] - 3s 33ms/step - loss: 0.5236 - accuracy: 0.7603 - val_loss: 0.5648 - val_accuracy: 0.6877\n",
            "Epoch 9/15\n",
            "101/101 [==============================] - 3s 29ms/step - loss: 0.5080 - accuracy: 0.7646 - val_loss: 0.5708 - val_accuracy: 0.6654\n",
            "Epoch 10/15\n",
            "101/101 [==============================] - 3s 30ms/step - loss: 0.4867 - accuracy: 0.7823 - val_loss: 0.5533 - val_accuracy: 0.6964\n",
            "Epoch 11/15\n",
            "101/101 [==============================] - 3s 28ms/step - loss: 0.4622 - accuracy: 0.8089 - val_loss: 0.5547 - val_accuracy: 0.6865\n",
            "Epoch 12/15\n",
            "101/101 [==============================] - 4s 38ms/step - loss: 0.4422 - accuracy: 0.8139 - val_loss: 0.5444 - val_accuracy: 0.7162\n",
            "Epoch 13/15\n",
            "101/101 [==============================] - 3s 29ms/step - loss: 0.4242 - accuracy: 0.8247 - val_loss: 0.5431 - val_accuracy: 0.7150\n",
            "Epoch 14/15\n",
            "101/101 [==============================] - 3s 29ms/step - loss: 0.4083 - accuracy: 0.8284 - val_loss: 0.5420 - val_accuracy: 0.7138\n",
            "Epoch 15/15\n",
            "101/101 [==============================] - 3s 28ms/step - loss: 0.3862 - accuracy: 0.8442 - val_loss: 0.5511 - val_accuracy: 0.7001\n",
            "Fold 2 - Validation loss: 0.5510768294334412, Validation accuracy: 0.7001239061355591\n",
            "Fold 3/5\n",
            "**************************reintializing****************\n",
            "before training the current validation score is  [0.3574787378311157, 0.8438661694526672]\n",
            "Epoch 1/15\n",
            "101/101 [==============================] - 5s 32ms/step - loss: 0.4184 - accuracy: 0.8185 - val_loss: 0.3453 - val_accuracy: 0.8910\n",
            "Epoch 2/15\n",
            "101/101 [==============================] - 3s 29ms/step - loss: 0.3990 - accuracy: 0.8238 - val_loss: 0.3401 - val_accuracy: 0.8885\n",
            "Epoch 3/15\n",
            "101/101 [==============================] - 3s 30ms/step - loss: 0.3749 - accuracy: 0.8473 - val_loss: 0.3343 - val_accuracy: 0.9021\n",
            "Epoch 4/15\n",
            "101/101 [==============================] - 3s 28ms/step - loss: 0.3665 - accuracy: 0.8458 - val_loss: 0.3279 - val_accuracy: 0.8922\n",
            "Epoch 5/15\n",
            "101/101 [==============================] - 3s 31ms/step - loss: 0.3396 - accuracy: 0.8653 - val_loss: 0.3257 - val_accuracy: 0.8612\n",
            "Epoch 6/15\n",
            "101/101 [==============================] - 3s 31ms/step - loss: 0.3295 - accuracy: 0.8696 - val_loss: 0.3201 - val_accuracy: 0.8996\n",
            "Epoch 7/15\n",
            "101/101 [==============================] - 3s 28ms/step - loss: 0.3195 - accuracy: 0.8705 - val_loss: 0.3127 - val_accuracy: 0.8897\n",
            "Epoch 8/15\n",
            "101/101 [==============================] - 3s 32ms/step - loss: 0.3008 - accuracy: 0.8798 - val_loss: 0.3244 - val_accuracy: 0.8463\n",
            "Epoch 9/15\n",
            "101/101 [==============================] - 3s 30ms/step - loss: 0.2854 - accuracy: 0.8981 - val_loss: 0.3062 - val_accuracy: 0.8786\n",
            "Epoch 10/15\n",
            "101/101 [==============================] - 3s 31ms/step - loss: 0.2769 - accuracy: 0.8950 - val_loss: 0.3031 - val_accuracy: 0.8823\n",
            "Epoch 11/15\n",
            "101/101 [==============================] - 3s 30ms/step - loss: 0.2605 - accuracy: 0.9034 - val_loss: 0.3116 - val_accuracy: 0.8513\n",
            "Epoch 12/15\n",
            "101/101 [==============================] - 3s 33ms/step - loss: 0.2468 - accuracy: 0.9111 - val_loss: 0.2999 - val_accuracy: 0.8773\n",
            "Epoch 13/15\n",
            "101/101 [==============================] - 3s 28ms/step - loss: 0.2407 - accuracy: 0.9120 - val_loss: 0.3014 - val_accuracy: 0.8612\n",
            "Epoch 14/15\n",
            "101/101 [==============================] - 3s 34ms/step - loss: 0.2286 - accuracy: 0.9238 - val_loss: 0.2961 - val_accuracy: 0.8773\n",
            "Epoch 15/15\n",
            "101/101 [==============================] - 3s 29ms/step - loss: 0.2179 - accuracy: 0.9192 - val_loss: 0.3130 - val_accuracy: 0.8439\n",
            "Fold 3 - Validation loss: 0.31302109360694885, Validation accuracy: 0.8438661694526672\n",
            "Fold 4/5\n",
            "**************************reintializing****************\n",
            "before training the current validation score is  [0.17399822175502777, 0.9355638027191162]\n",
            "Epoch 1/15\n",
            "101/101 [==============================] - 7s 29ms/step - loss: 0.2474 - accuracy: 0.9055 - val_loss: 0.1697 - val_accuracy: 0.9579\n",
            "Epoch 2/15\n",
            "101/101 [==============================] - 3s 31ms/step - loss: 0.2330 - accuracy: 0.9136 - val_loss: 0.1733 - val_accuracy: 0.9306\n",
            "Epoch 3/15\n",
            "101/101 [==============================] - 3s 28ms/step - loss: 0.2229 - accuracy: 0.9213 - val_loss: 0.1662 - val_accuracy: 0.9554\n",
            "Epoch 4/15\n",
            "101/101 [==============================] - 3s 31ms/step - loss: 0.2115 - accuracy: 0.9254 - val_loss: 0.1677 - val_accuracy: 0.9529\n",
            "Epoch 5/15\n",
            "101/101 [==============================] - 3s 28ms/step - loss: 0.2015 - accuracy: 0.9288 - val_loss: 0.1657 - val_accuracy: 0.9356\n",
            "Epoch 6/15\n",
            "101/101 [==============================] - 3s 34ms/step - loss: 0.1940 - accuracy: 0.9337 - val_loss: 0.1596 - val_accuracy: 0.9542\n",
            "Epoch 7/15\n",
            "101/101 [==============================] - 3s 29ms/step - loss: 0.1825 - accuracy: 0.9393 - val_loss: 0.1576 - val_accuracy: 0.9480\n",
            "Epoch 8/15\n",
            "101/101 [==============================] - 3s 28ms/step - loss: 0.1749 - accuracy: 0.9412 - val_loss: 0.1751 - val_accuracy: 0.9145\n",
            "Epoch 9/15\n",
            "101/101 [==============================] - 3s 31ms/step - loss: 0.1749 - accuracy: 0.9384 - val_loss: 0.1548 - val_accuracy: 0.9517\n",
            "Epoch 10/15\n",
            "101/101 [==============================] - 3s 28ms/step - loss: 0.1646 - accuracy: 0.9461 - val_loss: 0.1535 - val_accuracy: 0.9492\n",
            "Epoch 11/15\n",
            "101/101 [==============================] - 3s 32ms/step - loss: 0.1565 - accuracy: 0.9418 - val_loss: 0.1648 - val_accuracy: 0.9257\n",
            "Epoch 12/15\n",
            "101/101 [==============================] - 3s 29ms/step - loss: 0.1501 - accuracy: 0.9517 - val_loss: 0.1516 - val_accuracy: 0.9455\n",
            "Epoch 13/15\n",
            "101/101 [==============================] - 3s 29ms/step - loss: 0.1419 - accuracy: 0.9594 - val_loss: 0.1523 - val_accuracy: 0.9442\n",
            "Epoch 14/15\n",
            "101/101 [==============================] - 3s 28ms/step - loss: 0.1386 - accuracy: 0.9576 - val_loss: 0.1500 - val_accuracy: 0.9455\n",
            "Epoch 15/15\n",
            "101/101 [==============================] - 3s 33ms/step - loss: 0.1334 - accuracy: 0.9591 - val_loss: 0.1498 - val_accuracy: 0.9467\n",
            "Fold 4 - Validation loss: 0.1498032808303833, Validation accuracy: 0.9467162489891052\n",
            "Fold 5/5\n",
            "**************************reintializing****************\n",
            "before training the current validation score is  [0.08184138685464859, 0.9900867342948914]\n",
            "Epoch 1/15\n",
            "101/101 [==============================] - 5s 33ms/step - loss: 0.1474 - accuracy: 0.9501 - val_loss: 0.0854 - val_accuracy: 0.9839\n",
            "Epoch 2/15\n",
            "101/101 [==============================] - 4s 41ms/step - loss: 0.1418 - accuracy: 0.9545 - val_loss: 0.0800 - val_accuracy: 0.9888\n",
            "Epoch 3/15\n",
            "101/101 [==============================] - 4s 36ms/step - loss: 0.1336 - accuracy: 0.9579 - val_loss: 0.0823 - val_accuracy: 0.9851\n",
            "Epoch 4/15\n",
            "101/101 [==============================] - 3s 29ms/step - loss: 0.1270 - accuracy: 0.9582 - val_loss: 0.0796 - val_accuracy: 0.9851\n",
            "Epoch 5/15\n",
            "101/101 [==============================] - 3s 30ms/step - loss: 0.1229 - accuracy: 0.9573 - val_loss: 0.0781 - val_accuracy: 0.9839\n",
            "Epoch 6/15\n",
            " 94/101 [==========================>...] - ETA: 6s - loss: 0.1135 - accuracy: 0.9661"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-276cef4d9d45>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'before training the current validation score is '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbefore_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m# Train the model for this fold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;31m# Evaluate the model on the validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "with adam optimizer with 0.001 learning rate we are geting 60%\n"
      ],
      "metadata": {
        "id": "lLiSsTgcwngp"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZWvYnpXN4ZTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "it is using adam opttimizer with unknown learning rate"
      ],
      "metadata": {
        "id": "XVJlxdZ9sahC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize k-fold cross-validation\n",
        "kf = KFold(n_splits=K_FOLDS, shuffle=True)\n",
        "for train_index, val_index in kf.split(train_input):\n",
        "  scores = model.evaluate(x_val, y_val, verbose=0)\n",
        "  print(f\"Fold {fold} - Validation loss: {scores[0]}, Validation accuracy: {scores[1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "id": "hQ62XSwQ4aHf",
        "outputId": "d6c3f19d-602e-4114-d6b2-bd1e0c61fc4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 5 - Validation loss: 0.07562540471553802, Validation accuracy: 0.9851301312446594\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-43021de265d5>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mkf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK_FOLDS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Fold {fold} - Validation loss: {scores[0]}, Validation accuracy: {scores[1]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   2070\u001b[0m                         ):\n\u001b[1;32m   2071\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2072\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2073\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2074\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(train_input,train_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PNkqRte3Q1J",
        "outputId": "a969c5de-e8ea-436c-f4b1-dc5940ce7c2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "127/127 [==============================] - 68s 536ms/step - loss: 0.5987 - accuracy: 0.8855\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5987412929534912, 0.8855302333831787]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1qN2KR8qD5z",
        "outputId": "cda35b69-eaf7-4db8-820a-9a1c9919dd5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "354/354 [==============================] - 145s 397ms/step - loss: 0.6912 - accuracy: 0.5508 - val_loss: 0.6876 - val_accuracy: 0.5888\n",
            "Epoch 2/100\n",
            "354/354 [==============================] - 607s 2s/step - loss: 0.6876 - accuracy: 0.5681 - val_loss: 0.6833 - val_accuracy: 0.5904\n",
            "Epoch 3/100\n",
            "354/354 [==============================] - 97s 272ms/step - loss: 0.6848 - accuracy: 0.5777 - val_loss: 0.6802 - val_accuracy: 0.5912\n",
            "Epoch 4/100\n",
            "354/354 [==============================] - 7s 21ms/step - loss: 0.6835 - accuracy: 0.5766 - val_loss: 0.6785 - val_accuracy: 0.5912\n",
            "Epoch 5/100\n",
            "354/354 [==============================] - 7s 18ms/step - loss: 0.6815 - accuracy: 0.5752 - val_loss: 0.6774 - val_accuracy: 0.5912\n",
            "Epoch 6/100\n",
            "354/354 [==============================] - 8s 22ms/step - loss: 0.6811 - accuracy: 0.5763 - val_loss: 0.6769 - val_accuracy: 0.5912\n",
            "Epoch 7/100\n",
            "354/354 [==============================] - 7s 20ms/step - loss: 0.6811 - accuracy: 0.5766 - val_loss: 0.6766 - val_accuracy: 0.5912\n",
            "Epoch 8/100\n",
            "354/354 [==============================] - 7s 19ms/step - loss: 0.6800 - accuracy: 0.5773 - val_loss: 0.6762 - val_accuracy: 0.5912\n",
            "Epoch 9/100\n",
            "352/354 [============================>.] - ETA: 0s - loss: 0.6808 - accuracy: 0.5788Learning rate reduced: 8.9999994e-05\n",
            "354/354 [==============================] - 7s 20ms/step - loss: 0.6810 - accuracy: 0.5781 - val_loss: 0.6763 - val_accuracy: 0.5912\n",
            "Epoch 10/100\n",
            "354/354 [==============================] - 6s 18ms/step - loss: 0.6806 - accuracy: 0.5766 - val_loss: 0.6761 - val_accuracy: 0.5912\n",
            "Epoch 11/100\n",
            "354/354 [==============================] - 7s 21ms/step - loss: 0.6800 - accuracy: 0.5777 - val_loss: 0.6760 - val_accuracy: 0.5912\n",
            "Epoch 12/100\n",
            "354/354 [==============================] - 7s 19ms/step - loss: 0.6808 - accuracy: 0.5773 - val_loss: 0.6759 - val_accuracy: 0.5912\n",
            "Epoch 13/100\n",
            "354/354 [==============================] - 8s 21ms/step - loss: 0.6792 - accuracy: 0.5773 - val_loss: 0.6757 - val_accuracy: 0.5912\n",
            "Epoch 14/100\n",
            "354/354 [==============================] - 7s 19ms/step - loss: 0.6791 - accuracy: 0.5766 - val_loss: 0.6756 - val_accuracy: 0.5912\n",
            "Epoch 15/100\n",
            "354/354 [==============================] - ETA: 0s - loss: 0.6794 - accuracy: 0.5773Learning rate reduced: 8.099999e-05\n",
            "354/354 [==============================] - 7s 21ms/step - loss: 0.6794 - accuracy: 0.5773 - val_loss: 0.6756 - val_accuracy: 0.5912\n",
            "Epoch 16/100\n",
            "354/354 [==============================] - 6s 17ms/step - loss: 0.6794 - accuracy: 0.5777 - val_loss: 0.6756 - val_accuracy: 0.5912\n",
            "Epoch 17/100\n",
            "354/354 [==============================] - 7s 20ms/step - loss: 0.6782 - accuracy: 0.5773 - val_loss: 0.6754 - val_accuracy: 0.5912\n",
            "Epoch 18/100\n",
            "354/354 [==============================] - 7s 19ms/step - loss: 0.6799 - accuracy: 0.5770 - val_loss: 0.6755 - val_accuracy: 0.5912\n",
            "Epoch 19/100\n",
            "354/354 [==============================] - 8s 23ms/step - loss: 0.6784 - accuracy: 0.5777 - val_loss: 0.6754 - val_accuracy: 0.5912\n",
            "Epoch 20/100\n",
            "354/354 [==============================] - 6s 18ms/step - loss: 0.6775 - accuracy: 0.5773 - val_loss: 0.6753 - val_accuracy: 0.5912\n",
            "Epoch 21/100\n",
            "354/354 [==============================] - ETA: 0s - loss: 0.6775 - accuracy: 0.5781Learning rate reduced: 7.289999e-05\n",
            "354/354 [==============================] - 7s 20ms/step - loss: 0.6775 - accuracy: 0.5781 - val_loss: 0.6752 - val_accuracy: 0.5912\n",
            "Epoch 22/100\n",
            "354/354 [==============================] - 7s 19ms/step - loss: 0.6772 - accuracy: 0.5777 - val_loss: 0.6751 - val_accuracy: 0.5912\n",
            "Epoch 23/100\n",
            "354/354 [==============================] - 6s 18ms/step - loss: 0.6771 - accuracy: 0.5773 - val_loss: 0.6751 - val_accuracy: 0.5912\n",
            "Epoch 24/100\n",
            "354/354 [==============================] - 7s 19ms/step - loss: 0.6764 - accuracy: 0.5773 - val_loss: 0.6750 - val_accuracy: 0.5912\n",
            "Epoch 25/100\n",
            "354/354 [==============================] - 6s 18ms/step - loss: 0.6764 - accuracy: 0.5773 - val_loss: 0.6750 - val_accuracy: 0.5912\n",
            "Epoch 26/100\n",
            "354/354 [==============================] - 7s 20ms/step - loss: 0.6771 - accuracy: 0.5781 - val_loss: 0.6750 - val_accuracy: 0.5912\n",
            "Epoch 27/100\n",
            "352/354 [============================>.] - ETA: 0s - loss: 0.6756 - accuracy: 0.5785Learning rate reduced: 6.560999e-05\n",
            "354/354 [==============================] - 7s 19ms/step - loss: 0.6759 - accuracy: 0.5777 - val_loss: 0.6749 - val_accuracy: 0.5912\n",
            "Epoch 28/100\n",
            "354/354 [==============================] - 7s 21ms/step - loss: 0.6766 - accuracy: 0.5773 - val_loss: 0.6749 - val_accuracy: 0.5912\n",
            "Epoch 29/100\n",
            "354/354 [==============================] - 7s 19ms/step - loss: 0.6754 - accuracy: 0.5777 - val_loss: 0.6748 - val_accuracy: 0.5912\n",
            "Epoch 30/100\n",
            "354/354 [==============================] - 7s 19ms/step - loss: 0.6754 - accuracy: 0.5773 - val_loss: 0.6748 - val_accuracy: 0.5912\n",
            "Epoch 31/100\n",
            "354/354 [==============================] - 6s 17ms/step - loss: 0.6752 - accuracy: 0.5770 - val_loss: 0.6747 - val_accuracy: 0.5912\n",
            "Epoch 32/100\n",
            "354/354 [==============================] - 8s 21ms/step - loss: 0.6756 - accuracy: 0.5770 - val_loss: 0.6747 - val_accuracy: 0.5912\n",
            "Epoch 33/100\n",
            "353/354 [============================>.] - ETA: 0s - loss: 0.6740 - accuracy: 0.5775Learning rate reduced: 5.9048987e-05\n",
            "354/354 [==============================] - 6s 18ms/step - loss: 0.6739 - accuracy: 0.5777 - val_loss: 0.6746 - val_accuracy: 0.5912\n",
            "Epoch 34/100\n",
            "354/354 [==============================] - 8s 22ms/step - loss: 0.6739 - accuracy: 0.5773 - val_loss: 0.6746 - val_accuracy: 0.5912\n",
            "Epoch 35/100\n",
            "354/354 [==============================] - 7s 20ms/step - loss: 0.6728 - accuracy: 0.5773 - val_loss: 0.6744 - val_accuracy: 0.5912\n",
            "Epoch 36/100\n",
            "354/354 [==============================] - 7s 20ms/step - loss: 0.6740 - accuracy: 0.5777 - val_loss: 0.6744 - val_accuracy: 0.5912\n",
            "Epoch 37/100\n",
            "354/354 [==============================] - 7s 20ms/step - loss: 0.6739 - accuracy: 0.5777 - val_loss: 0.6744 - val_accuracy: 0.5912\n",
            "Epoch 38/100\n",
            "354/354 [==============================] - 6s 17ms/step - loss: 0.6743 - accuracy: 0.5773 - val_loss: 0.6744 - val_accuracy: 0.5912\n",
            "Epoch 39/100\n",
            "354/354 [==============================] - ETA: 0s - loss: 0.6737 - accuracy: 0.5770Learning rate reduced: 5.3144086e-05\n",
            "354/354 [==============================] - 7s 20ms/step - loss: 0.6737 - accuracy: 0.5770 - val_loss: 0.6743 - val_accuracy: 0.5912\n",
            "Epoch 40/100\n",
            "354/354 [==============================] - 6s 17ms/step - loss: 0.6721 - accuracy: 0.5773 - val_loss: 0.6743 - val_accuracy: 0.5912\n",
            "Epoch 41/100\n",
            "354/354 [==============================] - 7s 21ms/step - loss: 0.6720 - accuracy: 0.5781 - val_loss: 0.6742 - val_accuracy: 0.5912\n",
            "Epoch 42/100\n",
            "354/354 [==============================] - 6s 17ms/step - loss: 0.6716 - accuracy: 0.5777 - val_loss: 0.6742 - val_accuracy: 0.5912\n",
            "Epoch 43/100\n",
            "354/354 [==============================] - 8s 21ms/step - loss: 0.6715 - accuracy: 0.5777 - val_loss: 0.6742 - val_accuracy: 0.5912\n",
            "Epoch 44/100\n",
            "354/354 [==============================] - 7s 19ms/step - loss: 0.6704 - accuracy: 0.5784 - val_loss: 0.6740 - val_accuracy: 0.5912\n",
            "Epoch 45/100\n",
            "354/354 [==============================] - ETA: 0s - loss: 0.6702 - accuracy: 0.5788Learning rate reduced: 4.7829675e-05\n",
            "354/354 [==============================] - 8s 22ms/step - loss: 0.6702 - accuracy: 0.5788 - val_loss: 0.6740 - val_accuracy: 0.5912\n",
            "Epoch 46/100\n",
            "354/354 [==============================] - 6s 18ms/step - loss: 0.6699 - accuracy: 0.5773 - val_loss: 0.6739 - val_accuracy: 0.5912\n",
            "Epoch 47/100\n",
            "354/354 [==============================] - 7s 20ms/step - loss: 0.6699 - accuracy: 0.5773 - val_loss: 0.6738 - val_accuracy: 0.5912\n",
            "Epoch 48/100\n",
            "354/354 [==============================] - 7s 20ms/step - loss: 0.6680 - accuracy: 0.5773 - val_loss: 0.6737 - val_accuracy: 0.5912\n",
            "Epoch 49/100\n",
            "354/354 [==============================] - 7s 20ms/step - loss: 0.6696 - accuracy: 0.5788 - val_loss: 0.6736 - val_accuracy: 0.5912\n",
            "Epoch 50/100\n",
            "354/354 [==============================] - 7s 21ms/step - loss: 0.6670 - accuracy: 0.5770 - val_loss: 0.6735 - val_accuracy: 0.5912\n",
            "Epoch 51/100\n",
            "354/354 [==============================] - ETA: 0s - loss: 0.6670 - accuracy: 0.5791Learning rate reduced: 4.3046708e-05\n",
            "354/354 [==============================] - 8s 22ms/step - loss: 0.6670 - accuracy: 0.5791 - val_loss: 0.6734 - val_accuracy: 0.5912\n",
            "Epoch 52/100\n",
            "354/354 [==============================] - 7s 20ms/step - loss: 0.6675 - accuracy: 0.5795 - val_loss: 0.6734 - val_accuracy: 0.5912\n",
            "Epoch 53/100\n",
            "354/354 [==============================] - 7s 19ms/step - loss: 0.6673 - accuracy: 0.5784 - val_loss: 0.6733 - val_accuracy: 0.5912\n",
            "Epoch 54/100\n",
            "354/354 [==============================] - 8s 21ms/step - loss: 0.6662 - accuracy: 0.5802 - val_loss: 0.6732 - val_accuracy: 0.5912\n",
            "Epoch 55/100\n",
            "354/354 [==============================] - 7s 19ms/step - loss: 0.6656 - accuracy: 0.5777 - val_loss: 0.6730 - val_accuracy: 0.5912\n",
            "Epoch 56/100\n",
            "354/354 [==============================] - 7s 20ms/step - loss: 0.6667 - accuracy: 0.5788 - val_loss: 0.6730 - val_accuracy: 0.5912\n",
            "Epoch 57/100\n",
            "354/354 [==============================] - ETA: 0s - loss: 0.6647 - accuracy: 0.5802Learning rate reduced: 3.8742037e-05\n",
            "354/354 [==============================] - 6s 18ms/step - loss: 0.6647 - accuracy: 0.5802 - val_loss: 0.6729 - val_accuracy: 0.5912\n",
            "Epoch 58/100\n",
            "354/354 [==============================] - 7s 20ms/step - loss: 0.6652 - accuracy: 0.5788 - val_loss: 0.6729 - val_accuracy: 0.5912\n",
            "Epoch 59/100\n",
            "354/354 [==============================] - 7s 19ms/step - loss: 0.6639 - accuracy: 0.5777 - val_loss: 0.6729 - val_accuracy: 0.5912\n",
            "Epoch 60/100\n",
            "354/354 [==============================] - 7s 20ms/step - loss: 0.6636 - accuracy: 0.5788 - val_loss: 0.6727 - val_accuracy: 0.5912\n",
            "Epoch 61/100\n",
            "354/354 [==============================] - 6s 17ms/step - loss: 0.6649 - accuracy: 0.5773 - val_loss: 0.6727 - val_accuracy: 0.5912\n",
            "Epoch 62/100\n",
            "354/354 [==============================] - 8s 22ms/step - loss: 0.6614 - accuracy: 0.5791 - val_loss: 0.6726 - val_accuracy: 0.5912\n",
            "Epoch 63/100\n",
            "354/354 [==============================] - ETA: 0s - loss: 0.6627 - accuracy: 0.5781Learning rate reduced: 3.4867833e-05\n",
            "354/354 [==============================] - 7s 19ms/step - loss: 0.6627 - accuracy: 0.5781 - val_loss: 0.6725 - val_accuracy: 0.5912\n",
            "Epoch 64/100\n",
            "354/354 [==============================] - 7s 19ms/step - loss: 0.6624 - accuracy: 0.5802 - val_loss: 0.6724 - val_accuracy: 0.5912\n",
            "Epoch 65/100\n",
            "354/354 [==============================] - 7s 20ms/step - loss: 0.6612 - accuracy: 0.5809 - val_loss: 0.6723 - val_accuracy: 0.5912\n",
            "Epoch 66/100\n",
            "354/354 [==============================] - 6s 18ms/step - loss: 0.6607 - accuracy: 0.5809 - val_loss: 0.6722 - val_accuracy: 0.5912\n",
            "Epoch 67/100\n",
            "354/354 [==============================] - 7s 19ms/step - loss: 0.6607 - accuracy: 0.5805 - val_loss: 0.6721 - val_accuracy: 0.5912\n",
            "Epoch 68/100\n",
            "354/354 [==============================] - 7s 18ms/step - loss: 0.6612 - accuracy: 0.5809 - val_loss: 0.6720 - val_accuracy: 0.5912\n",
            "Epoch 69/100\n",
            "353/354 [============================>.] - ETA: 0s - loss: 0.6597 - accuracy: 0.5814Learning rate reduced: 3.138105e-05\n",
            "354/354 [==============================] - 7s 19ms/step - loss: 0.6598 - accuracy: 0.5812 - val_loss: 0.6720 - val_accuracy: 0.5912\n",
            "Epoch 70/100\n",
            "354/354 [==============================] - 6s 18ms/step - loss: 0.6585 - accuracy: 0.5798 - val_loss: 0.6719 - val_accuracy: 0.5912\n",
            "Epoch 71/100\n",
            "354/354 [==============================] - 7s 19ms/step - loss: 0.6587 - accuracy: 0.5802 - val_loss: 0.6718 - val_accuracy: 0.5912\n",
            "Epoch 72/100\n",
            "354/354 [==============================] - 6s 18ms/step - loss: 0.6584 - accuracy: 0.5819 - val_loss: 0.6717 - val_accuracy: 0.5912\n",
            "Epoch 73/100\n",
            "354/354 [==============================] - 7s 21ms/step - loss: 0.6571 - accuracy: 0.5819 - val_loss: 0.6717 - val_accuracy: 0.5912\n",
            "Epoch 74/100\n",
            "354/354 [==============================] - 6s 18ms/step - loss: 0.6565 - accuracy: 0.5830 - val_loss: 0.6715 - val_accuracy: 0.5912\n",
            "Epoch 75/100\n",
            "354/354 [==============================] - ETA: 0s - loss: 0.6572 - accuracy: 0.5819Learning rate reduced: 2.8242943e-05\n",
            "354/354 [==============================] - 7s 19ms/step - loss: 0.6572 - accuracy: 0.5819 - val_loss: 0.6715 - val_accuracy: 0.5912\n",
            "Epoch 76/100\n",
            "354/354 [==============================] - 6s 18ms/step - loss: 0.6574 - accuracy: 0.5830 - val_loss: 0.6714 - val_accuracy: 0.5912\n",
            "Epoch 77/100\n",
            "354/354 [==============================] - 7s 19ms/step - loss: 0.6562 - accuracy: 0.5827 - val_loss: 0.6713 - val_accuracy: 0.5912\n",
            "Epoch 78/100\n",
            "354/354 [==============================] - 7s 19ms/step - loss: 0.6551 - accuracy: 0.5834 - val_loss: 0.6713 - val_accuracy: 0.5912\n",
            "Epoch 79/100\n",
            "354/354 [==============================] - 8s 21ms/step - loss: 0.6547 - accuracy: 0.5834 - val_loss: 0.6712 - val_accuracy: 0.5912\n",
            "Epoch 80/100\n",
            "354/354 [==============================] - 7s 19ms/step - loss: 0.6539 - accuracy: 0.5837 - val_loss: 0.6711 - val_accuracy: 0.5912\n",
            "Epoch 81/100\n",
            "354/354 [==============================] - ETA: 0s - loss: 0.6534 - accuracy: 0.5858Learning rate reduced: 2.5418647e-05\n",
            "354/354 [==============================] - 7s 21ms/step - loss: 0.6534 - accuracy: 0.5858 - val_loss: 0.6711 - val_accuracy: 0.5912\n",
            "Epoch 82/100\n",
            "354/354 [==============================] - 7s 21ms/step - loss: 0.6526 - accuracy: 0.5855 - val_loss: 0.6710 - val_accuracy: 0.5912\n",
            "Epoch 83/100\n",
            "354/354 [==============================] - 6s 18ms/step - loss: 0.6527 - accuracy: 0.5837 - val_loss: 0.6709 - val_accuracy: 0.5912\n",
            "Epoch 84/100\n",
            "354/354 [==============================] - 7s 19ms/step - loss: 0.6538 - accuracy: 0.5851 - val_loss: 0.6709 - val_accuracy: 0.5912\n",
            "Epoch 85/100\n",
            "354/354 [==============================] - 6s 18ms/step - loss: 0.6519 - accuracy: 0.5858 - val_loss: 0.6707 - val_accuracy: 0.5912\n",
            "Epoch 86/100\n",
            "354/354 [==============================] - 7s 19ms/step - loss: 0.6505 - accuracy: 0.5865 - val_loss: 0.6706 - val_accuracy: 0.5912\n",
            "Epoch 87/100\n",
            "354/354 [==============================] - ETA: 0s - loss: 0.6510 - accuracy: 0.5901Learning rate reduced: 2.2876782e-05\n",
            "354/354 [==============================] - 6s 18ms/step - loss: 0.6510 - accuracy: 0.5901 - val_loss: 0.6707 - val_accuracy: 0.5912\n",
            "Epoch 88/100\n",
            "354/354 [==============================] - 7s 19ms/step - loss: 0.6496 - accuracy: 0.5901 - val_loss: 0.6707 - val_accuracy: 0.5912\n",
            "Epoch 89/100\n",
            "354/354 [==============================] - 7s 19ms/step - loss: 0.6496 - accuracy: 0.5922 - val_loss: 0.6705 - val_accuracy: 0.5912\n",
            "Epoch 90/100\n",
            "354/354 [==============================] - 7s 20ms/step - loss: 0.6494 - accuracy: 0.5887 - val_loss: 0.6704 - val_accuracy: 0.5912\n",
            "Epoch 91/100\n",
            "354/354 [==============================] - 7s 19ms/step - loss: 0.6481 - accuracy: 0.5901 - val_loss: 0.6703 - val_accuracy: 0.5912\n",
            "Epoch 92/100\n",
            "354/354 [==============================] - 7s 21ms/step - loss: 0.6485 - accuracy: 0.5873 - val_loss: 0.6702 - val_accuracy: 0.5912\n",
            "Epoch 93/100\n",
            "353/354 [============================>.] - ETA: 0s - loss: 0.6467 - accuracy: 0.5924Learning rate reduced: 2.0589103e-05\n",
            "354/354 [==============================] - 6s 17ms/step - loss: 0.6467 - accuracy: 0.5926 - val_loss: 0.6702 - val_accuracy: 0.5912\n",
            "Epoch 94/100\n",
            "354/354 [==============================] - 7s 19ms/step - loss: 0.6472 - accuracy: 0.5880 - val_loss: 0.6701 - val_accuracy: 0.5912\n",
            "Epoch 95/100\n",
            "354/354 [==============================] - 6s 18ms/step - loss: 0.6476 - accuracy: 0.5915 - val_loss: 0.6701 - val_accuracy: 0.5912\n",
            "Epoch 96/100\n",
            "354/354 [==============================] - 7s 19ms/step - loss: 0.6440 - accuracy: 0.5890 - val_loss: 0.6700 - val_accuracy: 0.5912\n",
            "Epoch 97/100\n",
            "354/354 [==============================] - 6s 17ms/step - loss: 0.6462 - accuracy: 0.5919 - val_loss: 0.6700 - val_accuracy: 0.5912\n",
            "Epoch 98/100\n",
            "354/354 [==============================] - 7s 21ms/step - loss: 0.6455 - accuracy: 0.5933 - val_loss: 0.6699 - val_accuracy: 0.5912\n",
            "Epoch 99/100\n",
            "354/354 [==============================] - 7s 18ms/step - loss: 0.6445 - accuracy: 0.5940 - val_loss: 0.6699 - val_accuracy: 0.5921\n",
            "Epoch 100/100\n",
            "354/354 [==============================] - 7s 21ms/step - loss: 0.6448 - accuracy: 0.5940 - val_loss: 0.6699 - val_accuracy: 0.5921\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ccd1af0dae0>"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "BATCH_SIZE=8\n",
        "EPOCHS=100\n",
        "\n",
        "\n",
        "initial_learning_rate = 0.0001\n",
        "momentum = 0.9  # Optional: If you want to use momentum\n",
        "\n",
        "\n",
        "class LearningRateSchedulerWithPatience(Callback):\n",
        "    def __init__(self, initial_lr, patience, factor):\n",
        "        super().__init__()\n",
        "        self.initial_lr = initial_lr\n",
        "        self.patience = patience\n",
        "        self.factor = factor\n",
        "        self.best_val_acc = -np.inf\n",
        "        self.wait = 0\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        val_acc = logs.get('val_accuracy')\n",
        "\n",
        "        if val_acc > self.best_val_acc:\n",
        "            self.best_val_acc = val_acc\n",
        "            self.wait = 0\n",
        "        else:\n",
        "            self.wait += 1\n",
        "            if self.wait >= self.patience:\n",
        "                self.model.optimizer.lr = self.model.optimizer.lr * self.factor\n",
        "                self.wait = 0\n",
        "                print(\"Learning rate reduced:\", self.model.optimizer.lr.numpy())\n",
        "\n",
        "# Create the custom LearningRateSchedulerWithPatience callback\n",
        "lr_scheduler = LearningRateSchedulerWithPatience(initial_lr=initial_learning_rate, patience=6, factor=0.9)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # You can adjust this value\n",
        "learning_rate = 0.0001\n",
        "momentum = 0.9  # Optional: If you want to use momentum\n",
        "\n",
        "# Create the SGD optimizer\n",
        "sgd_optimizer = SGD(learning_rate=learning_rate, momentum=momentum)\n",
        "# Compile the model\n",
        "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.compile(loss='binary_crossentropy', optimizer=sgd_optimizer, metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_input,\n",
        "          train_output,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          validation_split=0.3,\n",
        "          epochs=EPOCHS,\n",
        "          callbacks=[lr_scheduler])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3n9dyeSbrLNJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5YGwHSCz2gvi"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-azu-06e2gs7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MbfF_6qW2gqV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c25wwRE12gnQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOyUvOc-2gkp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2RQ6f60e2ghz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CelRe4yi2ge3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bg35XP0U2gcA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "msrDjpr-2gZZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9JpW7Vo62gWl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUdN7V_P2gTv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_YVelkv62gQ7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oO7Ksi_T2gOS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JClJnWMx2gLf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kU6cJbsI2gI2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tx1sYb6P2gGH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "02MKu9O62gDZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CdOygo3V2gAz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CRZV8ldo2Zds"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jk3Y51u82Zxc"
      },
      "source": [
        "this is first code that is able to decrase below 6800"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RB8zSX4S2ZbF"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import SGD\n",
        "BATCH_SIZE=8\n",
        "EPOCHS=100\n",
        "\n",
        "\n",
        "  # You can adjust this value\n",
        "learning_rate = 0.00001\n",
        "momentum = 0.9  # Optional: If you want to use momentum\n",
        "\n",
        "# Create the SGD optimizer\n",
        "sgd_optimizer = SGD(learning_rate=learning_rate, momentum=momentum)\n",
        "# Compile the model\n",
        "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.compile(loss='binary_crossentropy', optimizer=sgd_optimizer, metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.fit(train_input,\n",
        "          train_output,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          validation_split=0.05,\n",
        "          epochs=EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFD3zLMy2ZYa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q81gYS072ZV5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}