{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFxByNCIGnPY",
        "outputId": "c9fd221a-45e0-4c1b-fe40-80595950e2a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nKmiPKvFZmh",
        "outputId": "3bc62e49-c182-42d1-a528-19d07e5c5056"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.31.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import XLMRobertaTokenizer, TFXLMRobertaModel\n"
      ],
      "metadata": {
        "id": "1tLt1GxAFmJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5g6ovAQzF0yT",
        "outputId": "c58e74ed-cf44-46af-d9a9-f2878cf15e3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKMDJ8Hci3tr",
        "outputId": "2bb3762b-7da6-4e55-90a4-bb6668097d41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.16.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.12.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.65.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.7.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (23.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klBHONb_jDrF",
        "outputId": "981ab169-1d05-48ec-b27b-e71b0088dd7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "    \n",
            "    A token is already saved on your machine. Run `huggingface-cli whoami` to get more information or `huggingface-cli logout` if you want to log out.\n",
            "    Setting a new token will erase the existing one.\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Token: \n",
            "Add token as git credential? (Y/n) Y\n",
            "Token is valid (permission: read).\n",
            "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
            "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
            "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
            "\n",
            "git config --global credential.helper store\n",
            "\n",
            "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
            "Token has not been saved to git credential helper.\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEmGWJDVkL4y",
        "outputId": "2a48ad85-3c4d-4aac-9918-82ec078c8c2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "    \n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Token: \n",
            "Add token as git credential? (Y/n) Y\n",
            "Token is valid (permission: read).\n",
            "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
            "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
            "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
            "\n",
            "git config --global credential.helper store\n",
            "\n",
            "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
            "Token has not been saved to git credential helper.\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "paste the token below\n",
        "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"
      ],
      "metadata": {
        "id": "wV5upnb1kX6P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model directly\n",
        "from transformers import AutoTokenizer, TFAutoModel\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Abhijnan/AxomiyaBERTa\",use_auth_token=True)\n",
        "bert_model = TFAutoModel.from_pretrained(\"Abhijnan/AxomiyaBERTa\",use_auth_token=True,from_pt=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5r27JRLShkN0",
        "outputId": "73f2d08d-5f0f-47bf-ed65-32bd7521740a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1714: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_utils.py:2634: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n",
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFAlbertModel: ['predictions.LayerNorm.weight', 'predictions.decoder.bias', 'albert.embeddings.position_ids', 'predictions.bias', 'predictions.dense.weight', 'predictions.decoder.weight', 'predictions.dense.bias', 'predictions.LayerNorm.bias']\n",
            "- This IS expected if you are initializing TFAlbertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFAlbertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights or buffers of the TF 2.0 model TFAlbertModel were not initialized from the PyTorch model and are newly initialized: ['albert.pooler.weight', 'albert.pooler.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Saving\n",
        "save_model = False\n",
        "model_weights_location = '/content/drive/MyDrive/hate rate/task 4/model saving/xlm-2lstm-2dense only/model_weights.pth'\n",
        "model_architecture_location = \"/content/drive/MyDrive/hate rate/task 4/model saving/xlm-2lstm-2dense only/model_architecture.pth\"\n",
        "\n",
        "# Model Training\n",
        "num_epochs = 2\n",
        "\n",
        "\n",
        "# Data Location\n",
        "data_file_location = '/content/drive/MyDrive/hate rate/task 4/dataset/train_AH_preprocessed.csv'\n",
        "\n",
        "# Fine-Tuning\n",
        "fine_tune_bert = False\n",
        "\n",
        "# Tokenization\n",
        "max_token_length = 190\n",
        "\n",
        "# LSTM Configuration\n",
        "first_lstm_bidirectional = True\n",
        "\n",
        "# Batch Size\n",
        "batch_size = 8\n",
        "\n",
        "# Trained Model Usage\n",
        "use_saved_model = False\n",
        "saved_model_weight_location = ''\n",
        "\n",
        "# Binary Classification Threshold\n",
        "classification_threshold = 0.5\n",
        "\n",
        "# Save Final Model\n",
        "save_final_model = False\n",
        "final_model_weight_location = ''\n",
        "final_model_architecture_location = ''\n",
        "\n",
        "# Save Training/Validation Accuracy Dataframe\n",
        "save_accuracy_dataframe = False\n",
        "accuracy_dataframe_location = ''\n",
        "\n",
        "# Test Data Usage\n",
        "validation_data_percentage = 0.0\n",
        "use_test_data = False\n",
        "\n",
        "# Current BERT Model\n",
        "model_name = \"xlm-roberta-base\"\n",
        "\n",
        "\n",
        "max_tokenization_length=128"
      ],
      "metadata": {
        "id": "hEwQMbMRFo3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "6zNvcGOhGfmh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(data_file_location)"
      ],
      "metadata": {
        "id": "l9_dXWNyGxaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#convert label to int\n",
        "output=pd.Series()\n",
        "for indx,row in df.iterrows():\n",
        "  current=row['task_1']\n",
        "  if(current==\"NOT\"):\n",
        "    output.at[indx]=0\n",
        "  else:\n",
        "    output.at[indx]=1\n",
        "df['output']=output\n",
        "\n",
        "\n",
        "#finding longest sentence\n",
        "maxx=0\n",
        "\n",
        "for s in df['text']:\n",
        "  s_len=len(s.split())\n",
        "  if(s_len>maxx):\n",
        "    sent=s\n",
        "  maxx=max(s_len,maxx)\n",
        "\n",
        "\n",
        "print(maxx)\n",
        "# Pad sequences to a fixed length (adjust MAX_LEN if needed)\n",
        "MAX_LEN = maxx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1OH98DiGbDY",
        "outputId": "b14cc012-1e89-43b4-901a-3d1de73c9b6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-5acdf9bf36d9>:2: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "  output=pd.Series()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "66\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "\n",
        "# Splitting the dataframe into train and test sets\n",
        "# _, datadf = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "train_df=df\n",
        "#train_df,data_df=train_test_split(df,test_size=validation_data_percentage,random_state=50)\n",
        "\n",
        "# if(use_test_data):\n",
        "#   val_df,test_df=train_test_split(data_df,test_size=0.5,random_state=100)\n",
        "#   test_df=test_df.reset_index(drop=True)\n",
        "# else:\n",
        "#   val_df=data_df\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#train_df,test_df=train_test_split(data_df,test_size=0.2,random_state=50)\n",
        "\n",
        "# Reset the index of the DataFrame\n",
        "train_df = train_df.reset_index(drop=True)\n",
        "# Reset the index of the DataFrame\n",
        "##val_df = val_df.reset_index(drop=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "x6cOLzqTGeJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make the model trainable (update weights during training)\n",
        "for param in bert_model.layers:\n",
        "    param.trainable = True\n"
      ],
      "metadata": {
        "id": "hBEe_1XRHcdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qz_RcWt_IFVd",
        "outputId": "b9368aeb-0598-4bb3-a150-299b58d1396d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'S. No.', 'text', 'task_1', 'preprocessed_text',\n",
              "       'output'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def get_embeddings(df):\n",
        "  train_input_ids = []\n",
        "  train_attention_masks = []\n",
        "  train_labels = []\n",
        "  for idx, row in df.iterrows():\n",
        "    #text=row['preprocessed_text']\n",
        "    text=row['text']\n",
        "    if(text=='None'):\n",
        "      text=''\n",
        "    if(text=='nan'):\n",
        "      text=''\n",
        "    label=row['output']\n",
        "\n",
        "    text_token=tokenizer(text,truncation=True,padding='max_length',max_length=180)\n",
        "    train_input_ids.append(text_token['input_ids'])\n",
        "    train_attention_masks.append(text_token['attention_mask'])\n",
        "    train_labels.append(label)\n",
        "\n",
        "  return train_input_ids,train_attention_masks,train_labels\n",
        "\n",
        "    # text_input=[text_token['input_ids'],text_token['attention_mask']]\n"
      ],
      "metadata": {
        "id": "8VJ37l2FHrOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_input_ids,train_attention_masks,train_labels=get_embeddings(train_df)\n",
        "\n"
      ],
      "metadata": {
        "id": "cyEtje1yPzT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_input_ids,val_attention_masks,val_labels=get_embeddings(val_df)"
      ],
      "metadata": {
        "id": "oXlcUL3XJN6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to numpy arrays\n",
        "import numpy as np\n",
        "train_input_ids = np.array(train_input_ids)\n",
        "train_attention_masks = np.array(train_attention_masks)\n",
        "train_labels = np.array(train_labels)\n",
        "\n"
      ],
      "metadata": {
        "id": "QpZvPGfnQJaz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "val_input_ids = np.array(val_input_ids)\n",
        "val_attention_masks = np.array(val_attention_masks)\n",
        "val_labels = np.array(val_labels)"
      ],
      "metadata": {
        "id": "Srd14MGYJQbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_input_ids.shape\n",
        "val_input_ids.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_CmvdlwhpXM",
        "outputId": "37a6b880-549c-4a1e-fa9f-f2fcaf3fa62c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(404, 128)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "IfuT8MM4Zjwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#this one is working fine\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    ({'input_ids': train_input_ids, 'attention_mask': train_attention_masks}, train_labels)\n",
        ").batch(batch_size)\n"
      ],
      "metadata": {
        "id": "Qyia8EFtQmZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    ({'input_ids': val_input_ids, 'attention_mask': val_attention_masks}, val_labels)\n",
        ").batch(batch_size)\n"
      ],
      "metadata": {
        "id": "gmLdBsGQJTxD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "205a8223-1627-43ce-aa6e-aa4b63ad96c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-a220f3290add>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m val_dataset = tf.data.Dataset.from_tensor_slices(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval_input_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval_attention_masks\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m ).batch(batch_size)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'val_input_ids' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ew6eXN09pIBd",
        "outputId": "ce4e60db-45fa-4c76-b407-f6c887fad3c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "transformers.tokenization_utils_base.BatchEncoding"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example sentence with a masked word\n",
        "sentence = \"সঁচাই পৃথিৱীখন যে ইমান সুন্দৰ\"\n",
        "\n",
        "# Tokenize the sentence\n",
        "inputs = tokenizer(sentence, return_tensors=\"tf\")\n",
        "type(inputs)\n",
        "# Generate predictions for the masked token\n",
        "outputs = bert_model(input_ids=inputs['input_ids'],attention_mask=inputs['attention_mask'])\n"
      ],
      "metadata": {
        "id": "2478Jn9ulifo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9VlMR0km-jq",
        "outputId": "088f35d9-02c8-419d-850c-946b64624c2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TFBaseModelOutputWithPooling(last_hidden_state=<tf.Tensor: shape=(1, 7, 768), dtype=float32, numpy=\n",
              "array([[[ 0.09786534, -0.21150309, -2.425629  , ...,  0.01420348,\n",
              "          1.42384   , -0.50649256],\n",
              "        [ 0.39720172, -1.359025  ,  0.46150923, ...,  0.7663466 ,\n",
              "         -1.1123885 , -1.4948075 ],\n",
              "        [ 1.5523579 , -1.0888412 , -1.9005821 , ...,  0.7507171 ,\n",
              "         -0.16748758, -2.0915804 ],\n",
              "        ...,\n",
              "        [ 2.1265585 ,  0.35555825, -0.9863867 , ..., -0.26307717,\n",
              "          0.6379828 , -1.8828936 ],\n",
              "        [ 1.8667408 ,  0.38056478, -1.3477347 , ..., -1.4901602 ,\n",
              "          0.7580342 , -2.543373  ],\n",
              "        [ 1.2044251 , -0.33213368, -0.00919001, ..., -0.2676668 ,\n",
              "          1.164377  , -2.3437982 ]]], dtype=float32)>, pooler_output=<tf.Tensor: shape=(1, 768), dtype=float32, numpy=\n",
              "array([[-5.57867169e-01, -4.20049299e-03,  6.57549202e-01,\n",
              "        -3.20209324e-01, -4.12219130e-02,  7.52124012e-01,\n",
              "         5.81624091e-01,  1.30223036e-01,  3.05482954e-01,\n",
              "         6.92129135e-01, -1.30099654e-01, -1.32519275e-01,\n",
              "        -7.47536302e-01,  3.07571776e-02, -1.91795290e-01,\n",
              "         6.17082417e-01, -5.97699821e-01,  5.93151629e-01,\n",
              "         5.83743572e-01, -3.72092649e-02, -2.08657503e-01,\n",
              "         3.01892340e-01, -3.86948474e-02, -5.73695719e-01,\n",
              "         2.66225517e-01,  3.86061609e-01,  3.85710210e-01,\n",
              "         1.68249130e-01, -6.52362227e-01,  5.56891859e-02,\n",
              "        -1.02961168e-01, -1.58847049e-01, -2.82988369e-01,\n",
              "        -5.14728546e-01, -4.97047067e-01,  4.49140728e-01,\n",
              "        -9.73852426e-02,  1.04719743e-01, -7.00558841e-01,\n",
              "        -5.37308976e-02, -5.73163211e-01, -8.40242565e-01,\n",
              "         3.13445106e-02, -3.90335679e-01,  5.95744327e-02,\n",
              "        -8.47775817e-01,  2.77157396e-01, -3.22917908e-01,\n",
              "         6.88655162e-03,  6.81581438e-01,  4.67247665e-01,\n",
              "         1.54339764e-02, -1.15490369e-01, -2.72509634e-01,\n",
              "         7.85839483e-02, -1.89767405e-01,  9.25459340e-02,\n",
              "         1.85057014e-01,  1.59072578e-01, -5.06725967e-01,\n",
              "        -7.21155643e-01, -6.52385592e-01, -3.60028327e-01,\n",
              "        -5.34440994e-01, -6.72677577e-01, -1.02443174e-01,\n",
              "         3.44873667e-01,  7.39817098e-02,  3.42117734e-02,\n",
              "        -1.33147776e-01,  3.15097302e-01, -2.58827150e-01,\n",
              "         1.33808583e-01,  1.46689594e-01, -8.06024492e-01,\n",
              "         3.10088247e-01,  2.63761520e-01, -6.72794342e-01,\n",
              "        -5.71395874e-01,  5.27956903e-01,  5.70888102e-01,\n",
              "         5.58575690e-02,  5.79526067e-01, -1.41314894e-01,\n",
              "        -2.25301862e-01,  2.36296728e-02,  7.02421725e-01,\n",
              "        -9.19344202e-02, -5.97618163e-01, -2.54538536e-01,\n",
              "         1.27725065e-01,  3.41421604e-01,  5.77626765e-01,\n",
              "        -3.12409580e-01,  4.36405003e-01,  4.48821753e-01,\n",
              "         2.38443896e-01,  6.28335401e-02, -7.27978908e-03,\n",
              "         8.59465361e-01,  1.99866667e-01, -3.62197518e-01,\n",
              "        -7.94872403e-01,  1.13930106e-01, -2.55520880e-01,\n",
              "        -7.47089565e-01, -6.34077609e-01, -2.57698029e-01,\n",
              "         2.69807518e-01, -4.17883515e-01, -5.90071559e-01,\n",
              "        -3.21616948e-01, -7.39802599e-01,  1.98448449e-01,\n",
              "         3.88457388e-01,  3.44059050e-01,  4.66569752e-01,\n",
              "         3.07075083e-01, -7.65725732e-01, -4.01620902e-02,\n",
              "         3.89974833e-01,  2.14596108e-01, -1.51589096e-01,\n",
              "        -8.44805837e-01, -4.28259045e-01, -7.70044684e-01,\n",
              "        -1.42811507e-01, -1.00825429e-01, -4.92123514e-01,\n",
              "        -4.16492045e-01,  5.90465069e-01, -1.00495555e-02,\n",
              "        -7.11065769e-01, -9.39675719e-02,  5.35714090e-01,\n",
              "        -2.03971848e-01,  4.99298990e-01, -3.66871357e-01,\n",
              "        -1.73069760e-01,  5.45019984e-01, -2.06092760e-01,\n",
              "         6.08638525e-01, -2.58730084e-01,  2.87355274e-01,\n",
              "        -2.57511616e-01, -4.92776573e-01, -1.90829828e-01,\n",
              "        -2.76094135e-02, -3.72039586e-01, -4.23120290e-01,\n",
              "        -4.64826822e-01, -1.77029550e-01, -5.40076733e-01,\n",
              "        -4.83129263e-01,  3.31412882e-01, -3.46742198e-02,\n",
              "         5.38051012e-04,  4.83584225e-01,  7.95191586e-01,\n",
              "         4.29222614e-01,  4.60709840e-01,  5.50739825e-01,\n",
              "        -6.85130209e-02, -2.19234943e-01, -2.00533390e-01,\n",
              "         6.05172873e-01,  4.44027066e-01,  5.44759870e-01,\n",
              "        -4.59979028e-02,  5.67592621e-01,  3.10049891e-01,\n",
              "         5.64740598e-01,  4.59769666e-01, -1.68433115e-02,\n",
              "         3.20538849e-01,  4.65902835e-01,  7.29932114e-02,\n",
              "        -3.99853259e-01, -1.84150994e-01, -5.02591252e-01,\n",
              "        -8.38185474e-02, -4.27124649e-01, -1.39094159e-01,\n",
              "        -6.00473344e-01, -2.17857808e-01, -1.95117489e-01,\n",
              "        -1.53213009e-01,  1.34878501e-01,  1.43538147e-01,\n",
              "        -1.43855333e-01, -7.08190501e-02,  5.81915796e-01,\n",
              "         5.29440939e-01, -2.11295590e-01, -4.62469041e-01,\n",
              "        -7.25379109e-01, -3.52580726e-01,  1.27744526e-01,\n",
              "         6.98259100e-02, -4.80414122e-01, -2.91954845e-01,\n",
              "         5.59486821e-02,  1.00066282e-01, -1.30939379e-01,\n",
              "        -3.23453993e-01,  7.43201673e-02, -3.11980486e-01,\n",
              "         4.98792768e-01,  5.67792505e-02, -5.22805452e-01,\n",
              "         1.46581471e-01, -2.45745145e-02,  6.90331399e-01,\n",
              "        -2.82672383e-02,  4.14873660e-02,  5.02546370e-01,\n",
              "         2.58907348e-01,  7.39333257e-02, -6.50833011e-01,\n",
              "         6.29655480e-01, -3.63296479e-01, -9.68532339e-02,\n",
              "        -1.61453322e-01, -2.82134295e-01,  2.40432858e-01,\n",
              "        -2.29406282e-01, -9.29325074e-02, -3.50822695e-02,\n",
              "         7.32158244e-01, -1.88802168e-01,  5.15013747e-02,\n",
              "        -4.16933179e-01, -2.56396055e-01, -1.98264897e-01,\n",
              "        -3.12501192e-01, -6.94430232e-01, -7.82650828e-01,\n",
              "         2.31817830e-02, -5.38997412e-01,  4.26747948e-01,\n",
              "         5.50827801e-01, -7.27452189e-02, -4.69516337e-01,\n",
              "         6.83341682e-01, -6.09158948e-02,  1.41940992e-02,\n",
              "         5.22881150e-01, -5.28068304e-01,  3.36120367e-01,\n",
              "         2.49582693e-01, -8.23758304e-01, -6.92326128e-01,\n",
              "        -3.54609609e-01, -1.89333245e-01, -3.11024457e-01,\n",
              "         1.38088688e-01, -3.90442848e-01,  3.36689025e-01,\n",
              "         3.33357573e-01,  3.42727512e-01,  4.30961490e-01,\n",
              "         4.45889458e-02,  1.53010696e-01, -9.60220098e-02,\n",
              "         4.40493554e-01, -4.32135642e-01, -1.62357122e-01,\n",
              "        -2.27158114e-01, -1.04759179e-01, -8.46563399e-01,\n",
              "        -2.58271754e-01,  3.09443831e-01,  1.12654211e-03,\n",
              "        -1.17406256e-01, -2.40286514e-01,  7.89074242e-01,\n",
              "         3.20898861e-01,  1.71932235e-01,  3.62524807e-01,\n",
              "        -2.96280295e-01, -7.87949115e-02, -4.22707349e-01,\n",
              "         2.47415289e-01, -7.36935958e-02, -3.78749043e-01,\n",
              "         5.51079333e-01,  8.10742438e-01, -1.36145934e-01,\n",
              "        -8.45567763e-01, -4.03660238e-01, -7.46143699e-01,\n",
              "        -4.99611378e-01, -2.70161122e-01,  8.41595650e-01,\n",
              "        -1.70567274e-01, -1.63408622e-01, -7.07648039e-01,\n",
              "         2.88587272e-01, -2.56229371e-01,  1.00289404e-01,\n",
              "         6.11212030e-02, -7.55149901e-01,  1.88599542e-01,\n",
              "         8.46591592e-02, -9.09266621e-02, -4.75297749e-01,\n",
              "         6.68629229e-01,  5.37292957e-01, -7.54364550e-01,\n",
              "        -2.75295824e-01,  6.51289403e-01,  5.58020830e-01,\n",
              "         1.92200113e-02, -3.41610640e-01, -3.44998777e-01,\n",
              "         5.22122383e-01,  2.75359511e-01,  1.63252890e-01,\n",
              "         1.51506010e-02, -6.38601303e-01,  2.93384969e-01,\n",
              "        -3.48767132e-01, -5.56224525e-01,  1.20389581e-01,\n",
              "         6.94010615e-01,  6.01614714e-02,  3.40057969e-01,\n",
              "        -5.04854739e-01,  4.24492598e-01, -7.13343546e-02,\n",
              "        -1.09076411e-01,  4.12669420e-01,  3.88023853e-02,\n",
              "        -2.67594159e-01,  3.27736527e-01,  2.85218135e-02,\n",
              "         4.26746517e-01,  4.21189904e-01, -1.54182777e-01,\n",
              "         2.99098074e-01, -3.69819313e-01,  7.23312557e-01,\n",
              "        -4.43368942e-01, -2.62866884e-01,  5.21806479e-01,\n",
              "         6.58252001e-01, -1.76138669e-01,  6.10281587e-01,\n",
              "         1.14060029e-01,  6.24244034e-01,  8.61366540e-02,\n",
              "        -5.95956326e-01, -5.05960226e-01,  5.75232029e-01,\n",
              "        -3.08311850e-01, -2.80283868e-01,  8.78246307e-01,\n",
              "         1.82188436e-01,  6.47729099e-01, -8.83100927e-02,\n",
              "         4.58272040e-01,  1.95344269e-01,  2.11203367e-01,\n",
              "        -6.04718626e-01, -5.83431363e-01,  6.32188320e-01,\n",
              "        -7.32065976e-01, -1.05454594e-01, -1.96889326e-01,\n",
              "         6.86836690e-02,  1.88834399e-01, -2.69869119e-01,\n",
              "        -1.07234143e-01, -1.76860169e-01,  7.53427073e-02,\n",
              "         7.08320960e-02,  5.32137036e-01, -2.34922484e-01,\n",
              "        -9.92193818e-05,  3.31048161e-01, -4.93936092e-01,\n",
              "         4.22259033e-01,  8.00603390e-01, -6.88054621e-01,\n",
              "        -2.97541887e-01, -1.47067919e-01,  9.22151208e-02,\n",
              "        -6.03675127e-01, -6.89111948e-01,  2.90886015e-01,\n",
              "         3.26790988e-01,  3.82008731e-01,  7.34452784e-01,\n",
              "         2.30606645e-01,  3.69658351e-01,  2.59100229e-01,\n",
              "        -5.91192722e-01, -5.68699360e-01,  2.47934796e-02,\n",
              "         5.29996693e-01,  2.45485082e-01, -1.14608400e-01,\n",
              "        -1.08808221e-03, -2.78971970e-01, -6.18437052e-01,\n",
              "         8.77813920e-02, -7.42844403e-01, -3.10063273e-01,\n",
              "        -3.79801154e-01,  3.12813997e-01,  2.21172810e-01,\n",
              "         1.79614797e-01, -9.28143710e-02, -3.81666690e-01,\n",
              "        -5.83510339e-01, -3.52047116e-01,  8.35847780e-02,\n",
              "         4.82159287e-01,  3.59476767e-02,  8.81237835e-02,\n",
              "        -1.12246729e-01,  4.25845027e-01,  3.80025208e-01,\n",
              "         5.03590405e-01,  5.07759809e-01,  6.78201854e-01,\n",
              "        -1.50435865e-01,  8.28441456e-02, -5.40216118e-02,\n",
              "        -7.10725367e-01,  3.87984097e-01, -1.31318390e-01,\n",
              "         3.32909465e-01,  5.06628811e-01, -6.97441399e-02,\n",
              "         2.68459141e-01, -2.28084236e-01,  2.54804492e-01,\n",
              "        -4.83849823e-01, -7.91193098e-02,  3.41796786e-01,\n",
              "        -6.87871516e-01,  5.10346234e-01,  4.32227254e-01,\n",
              "        -2.53588796e-01,  3.25151205e-01, -7.05812693e-01,\n",
              "         5.03037155e-01, -5.83621748e-02,  2.25560471e-01,\n",
              "         4.72535253e-01,  2.34547615e-01, -2.64289439e-01,\n",
              "        -6.33145571e-01, -6.82419062e-01, -5.95290542e-01,\n",
              "         7.13703275e-01, -5.54541826e-01,  1.75883919e-01,\n",
              "        -6.72385275e-01, -4.79923561e-02, -7.99115002e-01,\n",
              "        -7.75249422e-01, -3.31990212e-01, -3.75473976e-01,\n",
              "        -1.35479674e-01,  9.76703838e-02, -2.67035186e-01,\n",
              "        -4.92763847e-01,  6.39798462e-01, -2.97642678e-01,\n",
              "         3.13791722e-01,  7.74039388e-01,  6.93365753e-01,\n",
              "        -6.73163414e-01, -1.01557001e-02, -1.40166759e-01,\n",
              "         7.69187927e-01, -9.11201239e-01,  3.23584914e-01,\n",
              "         1.95193604e-01,  1.79552376e-01,  5.16231239e-01,\n",
              "        -2.30589166e-01,  8.55287164e-02, -2.82520175e-01,\n",
              "        -1.44643620e-01,  6.59347653e-01, -2.94713020e-01,\n",
              "        -6.68233037e-01,  6.79333135e-02, -4.01668876e-01,\n",
              "         4.54960585e-01, -4.86587614e-01,  4.47452754e-01,\n",
              "         3.20008188e-01, -1.52305171e-01,  6.87904537e-01,\n",
              "        -1.64126128e-01,  5.66918969e-01,  1.61899522e-01,\n",
              "        -5.19602537e-01,  4.33888733e-01,  6.38515115e-01,\n",
              "        -1.40421793e-01,  6.37277290e-02,  5.47514781e-02,\n",
              "        -3.52251492e-02, -3.50211561e-01,  3.54359984e-01,\n",
              "         1.16818167e-01,  2.82502204e-01,  4.29786712e-01,\n",
              "         1.47403970e-01,  1.55989110e-01, -7.05100358e-01,\n",
              "        -5.23933887e-01, -5.23081720e-02, -3.66881639e-01,\n",
              "        -3.79942954e-01,  1.28722921e-01, -4.66862828e-01,\n",
              "         2.56101102e-01, -3.21373641e-01, -6.09848976e-01,\n",
              "         9.15097669e-02,  1.38924599e-01,  3.64005774e-01,\n",
              "        -3.88449222e-01, -3.75915855e-01, -1.44003093e-01,\n",
              "         3.96457076e-01, -7.25836098e-01,  1.84190273e-01,\n",
              "         1.37773141e-01, -4.38169204e-02, -3.41242015e-01,\n",
              "         7.47909844e-02,  2.86777884e-01, -2.16414377e-01,\n",
              "        -6.19566560e-01,  2.50826806e-01, -8.97642672e-01,\n",
              "        -2.68657863e-01,  2.80567974e-01,  2.22436741e-01,\n",
              "         2.13653460e-01, -2.23821566e-01, -3.68458033e-02,\n",
              "         5.09110451e-01, -7.19381511e-01,  8.34099054e-02,\n",
              "        -1.08565725e-01,  7.69907951e-01, -3.60500544e-01,\n",
              "         4.64405268e-01, -2.21446268e-02,  6.89378560e-01,\n",
              "         1.57449752e-01,  1.77958935e-01,  2.94461489e-01,\n",
              "         7.52794445e-01, -1.44228488e-01,  7.64916778e-01,\n",
              "         6.87922016e-02,  4.87978905e-02,  5.27247451e-02,\n",
              "         8.34846497e-02, -3.56829137e-01,  1.05121136e-01,\n",
              "        -2.51704723e-01,  4.31857735e-01, -2.59101510e-01,\n",
              "        -1.17919736e-01, -2.13801011e-01,  2.42311701e-01,\n",
              "         3.30964804e-01, -8.23211789e-01, -6.76609501e-02,\n",
              "        -2.68206626e-01, -5.27236983e-02, -1.44676238e-01,\n",
              "         1.18578203e-01, -1.39853552e-01,  4.48197097e-01,\n",
              "        -8.86175707e-02,  3.14009339e-01,  6.16679667e-03,\n",
              "        -8.47568363e-02, -5.29681802e-01,  2.07472354e-01,\n",
              "         6.32026970e-01,  2.89703459e-01, -2.84686744e-01,\n",
              "        -1.91536903e-01,  5.77537775e-01,  2.39651054e-01,\n",
              "        -4.69824016e-01,  3.99170876e-01,  3.47315460e-01,\n",
              "         5.11630476e-01, -4.00937647e-01,  3.26562077e-01,\n",
              "         1.44775733e-01,  7.42898555e-03, -3.71607751e-01,\n",
              "         2.05977589e-01, -6.98735058e-01, -7.07539022e-01,\n",
              "         1.44198492e-01,  6.39030695e-01,  1.15390345e-02,\n",
              "        -1.91683823e-03, -7.16157258e-02,  3.81476194e-01,\n",
              "        -6.74386621e-01,  4.09377873e-01,  4.50531505e-02,\n",
              "         9.46912076e-03, -4.39846158e-01, -2.30542108e-01,\n",
              "        -6.05615616e-01, -5.55238724e-01, -1.37924701e-01,\n",
              "         1.12922288e-01,  5.68354547e-01, -7.49987364e-01,\n",
              "        -1.81120187e-01,  5.77217460e-01,  7.79976428e-01,\n",
              "         1.01831011e-01,  3.94087374e-01,  6.05538249e-01,\n",
              "        -1.70338795e-01,  3.71520787e-01, -3.20797682e-01,\n",
              "        -4.03916746e-01,  1.33799553e-01, -4.43763509e-02,\n",
              "        -3.96839380e-01, -4.63146456e-02, -4.38405842e-01,\n",
              "        -1.32903442e-01, -2.10496217e-01,  2.30215788e-01,\n",
              "        -1.45682050e-02, -3.88073266e-01, -6.02795303e-01,\n",
              "        -2.98013389e-01, -3.80029261e-01, -7.57311642e-01,\n",
              "         2.75136143e-01,  2.80564670e-02,  5.31822860e-01,\n",
              "        -2.41617903e-01, -2.00035468e-01, -2.89255440e-01,\n",
              "        -4.48525578e-01, -9.10094008e-02, -2.23107889e-01,\n",
              "         4.61646736e-01,  1.14968069e-01,  1.45310201e-02,\n",
              "        -5.15552536e-02,  1.48308307e-01,  3.20470124e-01,\n",
              "        -1.14710115e-01, -7.36206889e-01,  2.14739278e-01,\n",
              "        -2.09442694e-02, -9.47283283e-02,  1.96062490e-01,\n",
              "        -5.98445237e-01, -8.84716436e-02, -1.87726080e-01,\n",
              "        -9.13385630e-01,  2.21726716e-01, -2.19734028e-01,\n",
              "        -1.20872304e-01, -8.65645528e-01, -5.28982043e-01,\n",
              "        -2.45591387e-01,  1.01654403e-01,  1.48741320e-01,\n",
              "         2.53242552e-01,  3.72857928e-01, -9.56131294e-02,\n",
              "        -2.39385888e-01,  6.86746716e-01,  2.74135880e-02,\n",
              "        -3.29295933e-01, -9.78966132e-02,  4.19103712e-01,\n",
              "         7.11930990e-01, -6.01722181e-01,  5.35513580e-01,\n",
              "        -3.83597136e-01,  2.27118522e-01,  1.72440201e-01,\n",
              "        -5.00755966e-01, -3.40924650e-01, -3.23689401e-01,\n",
              "        -3.06731671e-01,  1.23975329e-01,  1.75954193e-01,\n",
              "        -5.42923331e-01,  2.22861126e-01,  1.52272657e-01,\n",
              "         2.19959706e-01,  3.59443247e-01,  7.31671512e-01,\n",
              "        -5.81478238e-01,  6.60361469e-01,  1.33931652e-01,\n",
              "        -2.13055760e-01, -3.04547578e-01,  6.82550445e-02,\n",
              "         5.26800752e-01,  3.76204193e-01,  4.11742300e-01,\n",
              "         2.36060813e-01,  2.65287936e-01,  6.78818703e-01,\n",
              "        -2.59698957e-01, -5.68357259e-02, -1.52555496e-01,\n",
              "         1.72038883e-01,  6.87250122e-02, -4.24379595e-02,\n",
              "        -6.39341295e-01,  4.49013412e-01, -5.56629479e-01,\n",
              "         7.12045372e-01, -1.79188907e-01,  3.06820124e-01,\n",
              "        -2.59406239e-01,  1.07624903e-01,  4.55346018e-01,\n",
              "        -1.64893717e-02,  2.10638955e-01, -6.15151405e-01,\n",
              "        -5.17942309e-01, -5.16447306e-01, -2.27183178e-01,\n",
              "        -2.37556826e-02,  8.10962543e-02, -6.12907529e-01,\n",
              "        -7.90532827e-02,  2.75580566e-02,  6.63073540e-01,\n",
              "         9.70768183e-02,  2.41718188e-01,  1.36675820e-01,\n",
              "         2.16444001e-01,  1.29559249e-01,  4.28591609e-01,\n",
              "        -5.44292688e-01, -5.95236480e-01,  2.83197701e-01,\n",
              "         8.53232667e-02,  3.96536082e-01, -5.03116846e-01,\n",
              "        -1.55013576e-01, -6.06834710e-01, -7.11822748e-01,\n",
              "         3.13344687e-01,  2.75834590e-01, -2.30355635e-01]], dtype=float32)>, hidden_states=None, attentions=None)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a=outputs.logits"
      ],
      "metadata": {
        "id": "oJrpXuFnl1H1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3y7_IBflq3y",
        "outputId": "7b6305ce-ef05-4f77-be3c-45ccf1cb8c25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 7, 32001])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the hidden states of the [CLS] token\n",
        "cls_hidden_state = outputs.last_hidden_state[:, 0, :]"
      ],
      "metadata": {
        "id": "nF-YF1Fhm4r-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from transformers import TFXLMRobertaModel\n",
        "\n",
        "# Define model configuration\n",
        "max_seq_length = 180\n",
        "\n",
        "\n",
        "lstm1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=128, return_sequences=True, return_state=True))\n",
        "# lstm2 = tf.keras.layers.LSTM(units=64, return_sequences=True, return_state=True)\n",
        "#lstm3 = tf.keras.layers.LSTM(units=64, return_sequences=True, return_state=True)\n",
        "\n",
        "dense_layers = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(units=256, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(units=128, activation='relu'),\n",
        "\n",
        "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(units=32, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=1)\n",
        "])\n",
        "\n",
        "sigmoid = tf.keras.layers.Activation('sigmoid')\n",
        "\n",
        "# Define input layers\n",
        "input_dict={\n",
        "'input_ids':tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name='input_ids'),\n",
        "'attention_mask':tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name='attention_mask')}\n",
        "\n",
        "# # XLM-Roberta outputs\n",
        "# xlm_output = xlm_roberta([input_ids, attention_mask])[0]\n",
        "# XLM-Roberta outputs\n",
        "xlm_output = bert_model(input_ids=input_dict['input_ids'], attention_mask=input_dict['attention_mask'])[0]\n",
        "\n",
        "# LSTM 1\n",
        "lstm_output, forward_hidden_state, forward_cell_state, backward_hidden_state, backward_cell_state= lstm1(xlm_output)\n",
        "\n",
        "# # LSTM 2 (feeding output of LSTM 1)\n",
        "_,lstm2_output, _ = lstm2(lstm_output)\n",
        "\n",
        "# Dense layers\n",
        "dense_output = dense_layers(lstm2_output)\n",
        "\n",
        "output = sigmoid(dense_output)\n",
        "output = tf.squeeze(output, axis=1)\n",
        "\n",
        "#model = tf.keras.Model(inputs=[input_ids, attention_mask], outputs=output)\n",
        "# Define the model\n",
        "model = tf.keras.Model(inputs=input_dict, outputs=output)\n",
        "# Move the model to GPU if available\n",
        "# if tf.config.list_physical_devices('GPU'):\n",
        "#     model = tf.keras.utils.multi_gpu_model(model, gpus=2)\n",
        "\n",
        "# Compile the model\n"
      ],
      "metadata": {
        "id": "lF4B0gfRIVFH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "n_epochs=100\n",
        "#optimizer = tf.keras.optimizers.legacy.AdamW(learning_rate=0.1, decay=0.001)\n",
        "optimizer=tf.keras.optimizers.AdamW(\n",
        "    learning_rate=0.001,\n",
        "    weight_decay=0.004)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Create ReduceLROnPlateau callback\n",
        "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', mode='min', factor=0.7, patience=1, verbose=1)\n",
        "\n",
        "# Train the model using fit method\n",
        "history = model.fit(\n",
        "    train_dataset,  # Replace with your training dataset\n",
        "    epochs=n_epochs,\n",
        "    callbacks=[lr_scheduler],\n",
        "    batch_size=32,\n",
        "    verbose=1,\n",
        "\n",
        "    use_multiprocessing=True\n",
        "\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "34r6Q5ASRi9A",
        "outputId": "3e045374-d250-49f8-ed25-83c7904e2a63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model/albert/pooler/kernel:0', 'tf_albert_model/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model/albert/pooler/kernel:0', 'tf_albert_model/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model/albert/pooler/kernel:0', 'tf_albert_model/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model/albert/pooler/kernel:0', 'tf_albert_model/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "505/505 [==============================] - ETA: 0s - loss: 0.6860 - accuracy: 0.1089"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r505/505 [==============================] - 144s 204ms/step - loss: 0.6860 - accuracy: 0.1089 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "505/505 [==============================] - ETA: 0s - loss: 0.6831 - accuracy: 0.1307"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r505/505 [==============================] - 94s 186ms/step - loss: 0.6831 - accuracy: 0.1307 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "505/505 [==============================] - ETA: 0s - loss: 0.6813 - accuracy: 0.1069"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r505/505 [==============================] - 94s 185ms/step - loss: 0.6813 - accuracy: 0.1069 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "505/505 [==============================] - ETA: 0s - loss: 0.6829 - accuracy: 0.1050"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r505/505 [==============================] - 94s 186ms/step - loss: 0.6829 - accuracy: 0.1050 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "505/505 [==============================] - ETA: 0s - loss: 0.6817 - accuracy: 0.1149"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r505/505 [==============================] - 94s 186ms/step - loss: 0.6817 - accuracy: 0.1149 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "505/505 [==============================] - ETA: 0s - loss: 0.6808 - accuracy: 0.1129"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r505/505 [==============================] - 94s 186ms/step - loss: 0.6808 - accuracy: 0.1129 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "505/505 [==============================] - ETA: 0s - loss: 0.6803 - accuracy: 0.1248"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r505/505 [==============================] - 94s 186ms/step - loss: 0.6803 - accuracy: 0.1248 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "505/505 [==============================] - ETA: 0s - loss: 0.6803 - accuracy: 0.1485"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r505/505 [==============================] - 94s 186ms/step - loss: 0.6803 - accuracy: 0.1485 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "505/505 [==============================] - ETA: 0s - loss: 0.6808 - accuracy: 0.1426"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r505/505 [==============================] - 94s 185ms/step - loss: 0.6808 - accuracy: 0.1426 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "505/505 [==============================] - ETA: 0s - loss: 0.6803 - accuracy: 0.1129"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r505/505 [==============================] - 94s 186ms/step - loss: 0.6803 - accuracy: 0.1129 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "505/505 [==============================] - ETA: 0s - loss: 0.6802 - accuracy: 0.1109"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r505/505 [==============================] - 94s 185ms/step - loss: 0.6802 - accuracy: 0.1109 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "434/505 [========================>.....] - ETA: 13s - loss: 0.6804 - accuracy: 0.1406"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-78-396e145bce5f>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Train the model using fit method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Replace with your training dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U6Q_qVd2mQwQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}