{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EaFY-_kLkKOz",
        "outputId": "e48cff85-ade4-4b1d-dec9-ed0966b8b7f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fasttext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8noY2moskmk9",
        "outputId": "878f4bf1-099a-4fce-c322-8021c851df40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/68.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/68.8 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.8/68.8 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pybind11>=2.2 (from fasttext)\n",
            "  Using cached pybind11-2.11.1-py3-none-any.whl (227 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext) (67.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fasttext) (1.23.5)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp310-cp310-linux_x86_64.whl size=4199768 sha256=aaac5cfa40194541a3da4ea8eb4fd13b38c1d9d08426fd3edc92261a23fce616\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/13/75/f811c84a8ab36eedbaef977a6a58a98990e8e0f1967f98f394\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.2 pybind11-2.11.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fasttext\n",
        "\n",
        "# Replace 'path_to_model.bin' with the actual path to your .bin file\n",
        "fasttext_model = fasttext.load_model('/content/drive/MyDrive/hate rate/task 1/embedding/Gujarati/cc.gu.300.bin')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--rcf2dNkohj",
        "outputId": "a4d02260-3258-4f95-9760-4e13a9e115e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install seqeval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oK4q6ZjvmXSq",
        "outputId": "7e5c8cbc-d279-4f6a-9865-a73738284a63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.2.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=c087a92254f40476985edea158a139ec30472aefbbc4c99451e4760605f35bd7\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import pickle\n",
        "import json\n",
        "import pandas as pd\n",
        "import sys\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "from tensorflow.keras.layers import Embedding\n",
        "import os\n",
        "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "Xmsmz-Hck4d1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_word_vectors(file_path):\n",
        "    word_vectors = {}\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            values = line.rstrip().split(' ')\n",
        "            word = values[0]\n",
        "            vector = [float(val) for val in values[1:]]\n",
        "            word_vectors[word] = vector\n",
        "    return word_vectors\n",
        "\n",
        "# Replace 'path_to_vectors.vec' with the actual path to your .vec file\n",
        "word_vectors = load_word_vectors('/content/drive/MyDrive/hate rate/task 1/embedding/Gujarati/cc.gu.300.vec')\n"
      ],
      "metadata": {
        "id": "Qrb8AQz_ksG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv('/content/drive/MyDrive/hate rate/task 1/pre_text/TRAIN_GUJARATI_TASK_1_3.csv')\n"
      ],
      "metadata": {
        "id": "lNrvituMktZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "ck4HA-kgnkw7",
        "outputId": "840f8220-f127-4ef8-b2de-89d9d900362a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Unnamed: 0.1  Unnamed: 0 tweet_id                 created_at  \\\n",
              "0               0           0   guj001  2023-05-19 15:44:55+00:00   \n",
              "1               1           1   guj002  2023-05-27 16:44:40+00:00   \n",
              "2               2           2   guj003  2023-05-25 03:56:05+00:00   \n",
              "3               3           3   guj004  2023-03-25 08:05:22+00:00   \n",
              "4               4           4   guj005  2023-05-24 07:01:42+00:00   \n",
              "..            ...         ...      ...                        ...   \n",
              "195           195         195   guj196  2023-03-25 16:10:38+00:00   \n",
              "196           196         196   guj197  2023-05-26 12:27:01+00:00   \n",
              "197           197         197   guj198  2023-05-27 07:26:02+00:00   \n",
              "198           198         198   guj199  2023-03-26 09:32:06+00:00   \n",
              "199           199         199   guj200  2023-05-23 13:30:01+00:00   \n",
              "\n",
              "                                                  text user_screen_name label  \\\n",
              "0    @username @username ઇ વાયડાઈ ના તું હાઈસ ડોબો ...     Red__chilli_   HOF   \n",
              "1    @username @username આવા હલકા કેટલા છે કાય ખબર ...  sureshn25559831   HOF   \n",
              "2    @username @username તારી જેમ અમે જ્ઞાતિ માં બટ...      chattansinh   HOF   \n",
              "3    @username આવું વાહિયાત ખાવા વાળા લોકો પણ છે 😈😈...        imkpbhatt   NOT   \n",
              "4    @username @username બેશક, હું તમને મૂર્ખ કહી શ...     irshadvihari   NOT   \n",
              "..                                                 ...              ...   ...   \n",
              "195  @username આજ વિદેશી પ્રિન્ટ મીડિયા માં રાહુલ ગ...   nitinchavda548   NOT   \n",
              "196  @username @username @username ભડવો નયન ચાદર મો...      chattansinh   HOF   \n",
              "197  @username ચોદીના તારા જેવા ને પાકિસ્તાન ભેગી ન...      Rana_Naidu_   HOF   \n",
              "198  @username @username @username @username @usern...       kkpatel852   NOT   \n",
              "199  પારકી પંચાત : નીતિન પટેલને કેમ ઉડી ગયો છે રસ? ...    Divya_Bhaskar   NOT   \n",
              "\n",
              "                                              pre_text  intlabel  \n",
              "0    ઇ વાયડાઈ ના તું હાઈસ ડોબો એક હવાઈ ગયું છે મગજ ...         1  \n",
              "1    આવા હલકા કેટલા છે કાય ખબર નથી પડતી આવા હલકા વિ...         1  \n",
              "2    તારી જેમ અમે જ્ઞાતિ માં બટાઇ ગયેલા નથી ટોપા અમ...         1  \n",
              "3                    આવું વાહિયાત ખાવા વાળા લોકો પણ છે         0  \n",
              "4    બેશક હું તમને મૂર્ખ કહી શકું છું મારા મતે મૂર્...         0  \n",
              "..                                                 ...       ...  \n",
              "195  આજ વિદેશી પ્રિન્ટ મીડિયા માં રાહુલ ગાંધી નું ઘ...         0  \n",
              "196                            ભડવો નયન ચાદર મોદ બેણચો         1  \n",
              "197  ચોદીના તારા જેવા ને પાકિસ્તાન ભેગી નું થઈ જવાય...         1  \n",
              "198            અને જો સરકારી કોઈ અધિકારી કચરો ફેંકે તો         0  \n",
              "199  પારકી પંચાત  નીતિન પટેલને કેમ ઉડી ગયો છે રસ ક્...         0  \n",
              "\n",
              "[200 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ec387c19-a032-4d27-a72e-fae924b438cf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>created_at</th>\n",
              "      <th>text</th>\n",
              "      <th>user_screen_name</th>\n",
              "      <th>label</th>\n",
              "      <th>pre_text</th>\n",
              "      <th>intlabel</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>guj001</td>\n",
              "      <td>2023-05-19 15:44:55+00:00</td>\n",
              "      <td>@username @username ઇ વાયડાઈ ના તું હાઈસ ડોબો ...</td>\n",
              "      <td>Red__chilli_</td>\n",
              "      <td>HOF</td>\n",
              "      <td>ઇ વાયડાઈ ના તું હાઈસ ડોબો એક હવાઈ ગયું છે મગજ ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>guj002</td>\n",
              "      <td>2023-05-27 16:44:40+00:00</td>\n",
              "      <td>@username @username આવા હલકા કેટલા છે કાય ખબર ...</td>\n",
              "      <td>sureshn25559831</td>\n",
              "      <td>HOF</td>\n",
              "      <td>આવા હલકા કેટલા છે કાય ખબર નથી પડતી આવા હલકા વિ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>guj003</td>\n",
              "      <td>2023-05-25 03:56:05+00:00</td>\n",
              "      <td>@username @username તારી જેમ અમે જ્ઞાતિ માં બટ...</td>\n",
              "      <td>chattansinh</td>\n",
              "      <td>HOF</td>\n",
              "      <td>તારી જેમ અમે જ્ઞાતિ માં બટાઇ ગયેલા નથી ટોપા અમ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>guj004</td>\n",
              "      <td>2023-03-25 08:05:22+00:00</td>\n",
              "      <td>@username આવું વાહિયાત ખાવા વાળા લોકો પણ છે 😈😈...</td>\n",
              "      <td>imkpbhatt</td>\n",
              "      <td>NOT</td>\n",
              "      <td>આવું વાહિયાત ખાવા વાળા લોકો પણ છે</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>guj005</td>\n",
              "      <td>2023-05-24 07:01:42+00:00</td>\n",
              "      <td>@username @username બેશક, હું તમને મૂર્ખ કહી શ...</td>\n",
              "      <td>irshadvihari</td>\n",
              "      <td>NOT</td>\n",
              "      <td>બેશક હું તમને મૂર્ખ કહી શકું છું મારા મતે મૂર્...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>195</td>\n",
              "      <td>195</td>\n",
              "      <td>guj196</td>\n",
              "      <td>2023-03-25 16:10:38+00:00</td>\n",
              "      <td>@username આજ વિદેશી પ્રિન્ટ મીડિયા માં રાહુલ ગ...</td>\n",
              "      <td>nitinchavda548</td>\n",
              "      <td>NOT</td>\n",
              "      <td>આજ વિદેશી પ્રિન્ટ મીડિયા માં રાહુલ ગાંધી નું ઘ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>196</td>\n",
              "      <td>196</td>\n",
              "      <td>guj197</td>\n",
              "      <td>2023-05-26 12:27:01+00:00</td>\n",
              "      <td>@username @username @username ભડવો નયન ચાદર મો...</td>\n",
              "      <td>chattansinh</td>\n",
              "      <td>HOF</td>\n",
              "      <td>ભડવો નયન ચાદર મોદ બેણચો</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>197</td>\n",
              "      <td>197</td>\n",
              "      <td>guj198</td>\n",
              "      <td>2023-05-27 07:26:02+00:00</td>\n",
              "      <td>@username ચોદીના તારા જેવા ને પાકિસ્તાન ભેગી ન...</td>\n",
              "      <td>Rana_Naidu_</td>\n",
              "      <td>HOF</td>\n",
              "      <td>ચોદીના તારા જેવા ને પાકિસ્તાન ભેગી નું થઈ જવાય...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>198</td>\n",
              "      <td>198</td>\n",
              "      <td>guj199</td>\n",
              "      <td>2023-03-26 09:32:06+00:00</td>\n",
              "      <td>@username @username @username @username @usern...</td>\n",
              "      <td>kkpatel852</td>\n",
              "      <td>NOT</td>\n",
              "      <td>અને જો સરકારી કોઈ અધિકારી કચરો ફેંકે તો</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>199</td>\n",
              "      <td>199</td>\n",
              "      <td>guj200</td>\n",
              "      <td>2023-05-23 13:30:01+00:00</td>\n",
              "      <td>પારકી પંચાત : નીતિન પટેલને કેમ ઉડી ગયો છે રસ? ...</td>\n",
              "      <td>Divya_Bhaskar</td>\n",
              "      <td>NOT</td>\n",
              "      <td>પારકી પંચાત  નીતિન પટેલને કેમ ઉડી ગયો છે રસ ક્...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200 rows × 9 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ec387c19-a032-4d27-a72e-fae924b438cf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ec387c19-a032-4d27-a72e-fae924b438cf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ec387c19-a032-4d27-a72e-fae924b438cf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-19e27524-4ea7-4f58-8890-edd8deaf5e9d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-19e27524-4ea7-4f58-8890-edd8deaf5e9d')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-19e27524-4ea7-4f58-8890-edd8deaf5e9d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#finding longest sentence\n",
        "maxx=0\n",
        "\n",
        "for s in df['text']:\n",
        "  s_len=len(s.split())\n",
        "  if(s_len>maxx):\n",
        "    sent=s\n",
        "  maxx=max(s_len,maxx)\n",
        "\n",
        "print(maxx)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "impadkURkuUS",
        "outputId": "ff66beb0-7eef-416a-c04d-cdc2abb56d5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df,val_df=train_test_split(df,test_size=0.1,random_state=50)"
      ],
      "metadata": {
        "id": "Da1IoxIEk0sy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM=300"
      ],
      "metadata": {
        "id": "UFbC5DT6lJtW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "IsXcg198lO0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Fit the tokenizer on the sentence corpus\n",
        "tokenizer = Tokenizer(filters='',oov_token='[OOV]')"
      ],
      "metadata": {
        "id": "W9-adt7-lQYA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "765d86d3-5d65-4045-9e55-897d36c67ab7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-48a095d20e37>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Step 1: Fit the tokenizer on the sentence corpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moov_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'[OOV]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'Tokenizer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "tokenizer.fit_on_texts(train_df['pre_text'].tolist())\n",
        "train_sequence=tokenizer.texts_to_sequences(train_df['pre_text'].values)\n",
        "val_sequence=tokenizer.texts_to_sequences(val_df['pre_text'].values)\n",
        "\n",
        "\n",
        "num_tokens=len(tokenizer.word_index)\n",
        "\n",
        "num_tokens=len(tokenizer.word_index)+1\n",
        "\n",
        "GLOVE_EMBEDDING_DIM=100\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Yx6KDMjXlaft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_sequence_length = 128"
      ],
      "metadata": {
        "id": "TXPtCMekmIRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import fasttext\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Pad sequences to a uniform length\n",
        "train_padded_sequences = pad_sequences(train_sequence, maxlen=max_sequence_length, padding='post', truncating='post')\n",
        "val_padded_sequences = pad_sequences(val_sequence, maxlen=max_sequence_length, padding='post', truncating='post')\n",
        "\n",
        "# Create the embedding matrix\n",
        "embedding_dim = 300  # Adjust based on your FastText embeddings\n",
        "num_words = len(tokenizer.word_index) + 1  # Add 1 for the padding token\n",
        "count_yes=0\n",
        "embedding_matrix = np.zeros((num_words, embedding_dim))\n",
        "word_embedding_not_found=[]\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if word in fasttext_model:\n",
        "        count_yes+=1\n",
        "        embedding_matrix[i] = fasttext_model[word]\n",
        "    else:\n",
        "      word_embedding_not_found.append(word)\n",
        "\n",
        "# Now you can use 'embedding_matrix' as the 'weights' parameter when creating the Embedding layer in your model\n",
        "print('number of words in fasttext of our tokenizer are : ',count_yes,' and total is ',num_words)"
      ],
      "metadata": {
        "id": "UJzKaVQklipS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_input=train_padded_sequences\n",
        "train_output=np.array(train_df['intlabel'])\n",
        "\n",
        "val_input=val_padded_sequences\n",
        "val_output=np.array(val_df['intlabel'])\n"
      ],
      "metadata": {
        "id": "Y09enWohnABK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, LSTM, Dense, Add, Input,Concatenate,Dropout\n",
        "from keras.layers import Input, Embedding, Conv1D, GlobalMaxPooling1D, Dense\n",
        "from keras.models import Model\n",
        "# Assuming you have loaded FastText embeddings into 'embedding_matrix'\n",
        "\n",
        "# Input layer\n",
        "input_layer = Input(shape=(max_sequence_length,))\n",
        "\n",
        "# Embedding layer\n",
        "embedding_layer = Embedding(input_dim=num_words,\n",
        "                            output_dim=embedding_dim,\n",
        "                            weights=[embedding_matrix],\n",
        "                            input_length=max_sequence_length,\n",
        "                            trainable=False)(input_layer)\n",
        "\n",
        "# Add a 1D convolutional layer\n",
        "conv_layer = Conv1D(filters=300, kernel_size=3, activation='relu', padding='same' )(embedding_layer)\n",
        "\n",
        "\n",
        "#max_pooling_layer = MaxPooling1D(pool_size=2)(conv_layer)\n",
        "# Second 1D convolutional layer\n",
        "conv_layer_2 = Conv1D(filters=300, kernel_size=2, activation='relu', padding='same')(conv_layer)\n",
        "# Apply global max pooling\n",
        "residual_connection = Add()([conv_layer_2, conv_layer])\n",
        "conv_layer_3 = Conv1D(filters=500, kernel_size=2, activation='relu')(residual_connection)\n",
        "conv_layer_3=Dropout(0.3)(conv_layer_3)\n",
        "conv_layer_4 = Conv1D(filters=300, kernel_size=1, activation='relu')(conv_layer_3)\n",
        "\n",
        "pooling_layer = GlobalMaxPooling1D()(conv_layer_4)\n",
        "\n",
        "# Add a dense layer\n",
        "dense_layer = Dense(50, activation='relu')(pooling_layer)\n",
        "\n",
        "# Output layer\n",
        "output_layer = Dense(1, activation='sigmoid')(dense_layer)\n",
        "\n",
        "\n",
        "# Create the model\n",
        "\n"
      ],
      "metadata": {
        "id": "5SfBt7y1pUXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "\n",
        "\n",
        "# Print the model summary\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E05XFNSmq6mx",
        "outputId": "2d0b1bff-5c5b-42df-e717-57540a74a538"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_14\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_19 (InputLayer)          [(None, 128)]        0           []                               \n",
            "                                                                                                  \n",
            " embedding_15 (Embedding)       (None, 128, 300)     529800      ['input_19[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_36 (Conv1D)             (None, 128, 300)     270300      ['embedding_15[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_37 (Conv1D)             (None, 128, 300)     180300      ['conv1d_36[0][0]']              \n",
            "                                                                                                  \n",
            " add_13 (Add)                   (None, 128, 300)     0           ['conv1d_37[0][0]',              \n",
            "                                                                  'conv1d_36[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_38 (Conv1D)             (None, 127, 500)     300500      ['add_13[0][0]']                 \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 127, 500)     0           ['conv1d_38[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_39 (Conv1D)             (None, 127, 300)     150300      ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " global_max_pooling1d_11 (Globa  (None, 300)         0           ['conv1d_39[0][0]']              \n",
            " lMaxPooling1D)                                                                                   \n",
            "                                                                                                  \n",
            " dense_22 (Dense)               (None, 50)           15050       ['global_max_pooling1d_11[0][0]']\n",
            "                                                                                                  \n",
            " dense_23 (Dense)               (None, 1)            51          ['dense_22[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,446,301\n",
            "Trainable params: 916,501\n",
            "Non-trainable params: 529,800\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.reset_states()\n"
      ],
      "metadata": {
        "id": "oQ_nV7krrwOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import AdamW\n",
        "BATCH_SIZE=32\n",
        "EPOCHS=1000\n",
        "\n",
        "\n",
        "learning_rate = 0.00005  # You can adjust this value\n",
        "optimizer = tf.keras.optimizers.AdamW(learning_rate=learning_rate)\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.fit(train_input,\n",
        "          train_output,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          validation_data=(val_input,val_output),\n",
        "          epochs=EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UzV0BxOVp6EY",
        "outputId": "17b9d34a-227e-46dd-c85a-18ffab039cd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "6/6 [==============================] - 5s 522ms/step - loss: 0.6949 - accuracy: 0.5056 - val_loss: 0.6904 - val_accuracy: 0.6000\n",
            "Epoch 2/1000\n",
            "6/6 [==============================] - 5s 833ms/step - loss: 0.6916 - accuracy: 0.5611 - val_loss: 0.6900 - val_accuracy: 0.5500\n",
            "Epoch 3/1000\n",
            "6/6 [==============================] - 3s 458ms/step - loss: 0.6888 - accuracy: 0.6167 - val_loss: 0.6898 - val_accuracy: 0.4500\n",
            "Epoch 4/1000\n",
            "6/6 [==============================] - 3s 468ms/step - loss: 0.6878 - accuracy: 0.6167 - val_loss: 0.6895 - val_accuracy: 0.5000\n",
            "Epoch 5/1000\n",
            "6/6 [==============================] - 3s 472ms/step - loss: 0.6856 - accuracy: 0.6111 - val_loss: 0.6894 - val_accuracy: 0.5500\n",
            "Epoch 6/1000\n",
            "6/6 [==============================] - 4s 660ms/step - loss: 0.6834 - accuracy: 0.6111 - val_loss: 0.6885 - val_accuracy: 0.5000\n",
            "Epoch 7/1000\n",
            "6/6 [==============================] - 4s 534ms/step - loss: 0.6829 - accuracy: 0.6222 - val_loss: 0.6878 - val_accuracy: 0.5000\n",
            "Epoch 8/1000\n",
            "6/6 [==============================] - 3s 472ms/step - loss: 0.6802 - accuracy: 0.5944 - val_loss: 0.6873 - val_accuracy: 0.5500\n",
            "Epoch 9/1000\n",
            "6/6 [==============================] - 3s 459ms/step - loss: 0.6772 - accuracy: 0.6000 - val_loss: 0.6865 - val_accuracy: 0.5500\n",
            "Epoch 10/1000\n",
            "6/6 [==============================] - 3s 511ms/step - loss: 0.6754 - accuracy: 0.6556 - val_loss: 0.6854 - val_accuracy: 0.5000\n",
            "Epoch 11/1000\n",
            "6/6 [==============================] - 4s 700ms/step - loss: 0.6724 - accuracy: 0.6889 - val_loss: 0.6845 - val_accuracy: 0.5000\n",
            "Epoch 12/1000\n",
            "6/6 [==============================] - 3s 456ms/step - loss: 0.6698 - accuracy: 0.6889 - val_loss: 0.6831 - val_accuracy: 0.5000\n",
            "Epoch 13/1000\n",
            "6/6 [==============================] - 3s 458ms/step - loss: 0.6684 - accuracy: 0.7056 - val_loss: 0.6822 - val_accuracy: 0.5000\n",
            "Epoch 14/1000\n",
            "6/6 [==============================] - 3s 470ms/step - loss: 0.6658 - accuracy: 0.7444 - val_loss: 0.6807 - val_accuracy: 0.5000\n",
            "Epoch 15/1000\n",
            "6/6 [==============================] - 5s 808ms/step - loss: 0.6630 - accuracy: 0.8222 - val_loss: 0.6795 - val_accuracy: 0.5000\n",
            "Epoch 16/1000\n",
            "6/6 [==============================] - 3s 470ms/step - loss: 0.6595 - accuracy: 0.7944 - val_loss: 0.6788 - val_accuracy: 0.5500\n",
            "Epoch 17/1000\n",
            "6/6 [==============================] - 3s 464ms/step - loss: 0.6572 - accuracy: 0.7722 - val_loss: 0.6776 - val_accuracy: 0.5000\n",
            "Epoch 18/1000\n",
            "6/6 [==============================] - 3s 467ms/step - loss: 0.6525 - accuracy: 0.8111 - val_loss: 0.6764 - val_accuracy: 0.4000\n",
            "Epoch 19/1000\n",
            "6/6 [==============================] - 4s 653ms/step - loss: 0.6467 - accuracy: 0.8833 - val_loss: 0.6748 - val_accuracy: 0.5500\n",
            "Epoch 20/1000\n",
            "6/6 [==============================] - 4s 538ms/step - loss: 0.6412 - accuracy: 0.8778 - val_loss: 0.6733 - val_accuracy: 0.5500\n",
            "Epoch 21/1000\n",
            "6/6 [==============================] - 3s 466ms/step - loss: 0.6384 - accuracy: 0.8778 - val_loss: 0.6714 - val_accuracy: 0.5000\n",
            "Epoch 22/1000\n",
            "6/6 [==============================] - 3s 458ms/step - loss: 0.6354 - accuracy: 0.8944 - val_loss: 0.6699 - val_accuracy: 0.5000\n",
            "Epoch 23/1000\n",
            "6/6 [==============================] - 3s 477ms/step - loss: 0.6264 - accuracy: 0.8833 - val_loss: 0.6676 - val_accuracy: 0.5000\n",
            "Epoch 24/1000\n",
            "6/6 [==============================] - 4s 719ms/step - loss: 0.6218 - accuracy: 0.9056 - val_loss: 0.6652 - val_accuracy: 0.4500\n",
            "Epoch 25/1000\n",
            "6/6 [==============================] - 3s 458ms/step - loss: 0.6140 - accuracy: 0.9111 - val_loss: 0.6637 - val_accuracy: 0.5000\n",
            "Epoch 26/1000\n",
            "6/6 [==============================] - 3s 456ms/step - loss: 0.6073 - accuracy: 0.9111 - val_loss: 0.6623 - val_accuracy: 0.4500\n",
            "Epoch 27/1000\n",
            "6/6 [==============================] - 3s 452ms/step - loss: 0.5977 - accuracy: 0.9167 - val_loss: 0.6593 - val_accuracy: 0.4500\n",
            "Epoch 28/1000\n",
            "6/6 [==============================] - 4s 734ms/step - loss: 0.5892 - accuracy: 0.8944 - val_loss: 0.6557 - val_accuracy: 0.5500\n",
            "Epoch 29/1000\n",
            "6/6 [==============================] - 3s 472ms/step - loss: 0.5821 - accuracy: 0.9167 - val_loss: 0.6567 - val_accuracy: 0.4000\n",
            "Epoch 30/1000\n",
            "6/6 [==============================] - 3s 469ms/step - loss: 0.5689 - accuracy: 0.9056 - val_loss: 0.6529 - val_accuracy: 0.4500\n",
            "Epoch 31/1000\n",
            "6/6 [==============================] - 3s 455ms/step - loss: 0.5553 - accuracy: 0.9111 - val_loss: 0.6486 - val_accuracy: 0.5500\n",
            "Epoch 32/1000\n",
            "6/6 [==============================] - 3s 534ms/step - loss: 0.5419 - accuracy: 0.9333 - val_loss: 0.6459 - val_accuracy: 0.5500\n",
            "Epoch 33/1000\n",
            "6/6 [==============================] - 4s 656ms/step - loss: 0.5281 - accuracy: 0.9167 - val_loss: 0.6432 - val_accuracy: 0.5000\n",
            "Epoch 34/1000\n",
            "6/6 [==============================] - 3s 466ms/step - loss: 0.5085 - accuracy: 0.9389 - val_loss: 0.6404 - val_accuracy: 0.5000\n",
            "Epoch 35/1000\n",
            "6/6 [==============================] - 3s 457ms/step - loss: 0.4954 - accuracy: 0.9167 - val_loss: 0.6400 - val_accuracy: 0.5000\n",
            "Epoch 36/1000\n",
            "6/6 [==============================] - 3s 472ms/step - loss: 0.4733 - accuracy: 0.9167 - val_loss: 0.6396 - val_accuracy: 0.5000\n",
            "Epoch 37/1000\n",
            "6/6 [==============================] - 5s 832ms/step - loss: 0.4487 - accuracy: 0.9667 - val_loss: 0.6400 - val_accuracy: 0.5000\n",
            "Epoch 38/1000\n",
            "6/6 [==============================] - 3s 469ms/step - loss: 0.4299 - accuracy: 0.9278 - val_loss: 0.6388 - val_accuracy: 0.5500\n",
            "Epoch 39/1000\n",
            "6/6 [==============================] - 3s 483ms/step - loss: 0.4103 - accuracy: 0.9444 - val_loss: 0.6460 - val_accuracy: 0.5000\n",
            "Epoch 40/1000\n",
            "6/6 [==============================] - 3s 472ms/step - loss: 0.3782 - accuracy: 0.9611 - val_loss: 0.6396 - val_accuracy: 0.5000\n",
            "Epoch 41/1000\n",
            "6/6 [==============================] - 4s 705ms/step - loss: 0.3564 - accuracy: 0.9611 - val_loss: 0.6452 - val_accuracy: 0.5000\n",
            "Epoch 42/1000\n",
            "6/6 [==============================] - 3s 511ms/step - loss: 0.3310 - accuracy: 0.9778 - val_loss: 0.6717 - val_accuracy: 0.4500\n",
            "Epoch 43/1000\n",
            "6/6 [==============================] - 3s 455ms/step - loss: 0.3074 - accuracy: 0.9833 - val_loss: 0.6606 - val_accuracy: 0.4500\n",
            "Epoch 44/1000\n",
            "6/6 [==============================] - 3s 457ms/step - loss: 0.2784 - accuracy: 0.9778 - val_loss: 0.6598 - val_accuracy: 0.5000\n",
            "Epoch 45/1000\n",
            "6/6 [==============================] - 3s 502ms/step - loss: 0.2535 - accuracy: 0.9722 - val_loss: 0.6797 - val_accuracy: 0.4500\n",
            "Epoch 46/1000\n",
            "6/6 [==============================] - 4s 696ms/step - loss: 0.2271 - accuracy: 0.9833 - val_loss: 0.6910 - val_accuracy: 0.4500\n",
            "Epoch 47/1000\n",
            "6/6 [==============================] - 3s 464ms/step - loss: 0.1990 - accuracy: 0.9944 - val_loss: 0.6902 - val_accuracy: 0.5000\n",
            "Epoch 48/1000\n",
            "6/6 [==============================] - 3s 472ms/step - loss: 0.1764 - accuracy: 1.0000 - val_loss: 0.7112 - val_accuracy: 0.4500\n",
            "Epoch 49/1000\n",
            "6/6 [==============================] - 3s 457ms/step - loss: 0.1552 - accuracy: 1.0000 - val_loss: 0.7134 - val_accuracy: 0.5000\n",
            "Epoch 50/1000\n",
            "6/6 [==============================] - 5s 818ms/step - loss: 0.1370 - accuracy: 1.0000 - val_loss: 0.7445 - val_accuracy: 0.5000\n",
            "Epoch 51/1000\n",
            "6/6 [==============================] - 3s 464ms/step - loss: 0.1175 - accuracy: 0.9944 - val_loss: 0.7371 - val_accuracy: 0.5000\n",
            "Epoch 52/1000\n",
            "6/6 [==============================] - 3s 457ms/step - loss: 0.1016 - accuracy: 1.0000 - val_loss: 0.7655 - val_accuracy: 0.4500\n",
            "Epoch 53/1000\n",
            "6/6 [==============================] - 3s 468ms/step - loss: 0.0894 - accuracy: 1.0000 - val_loss: 0.7739 - val_accuracy: 0.5000\n",
            "Epoch 54/1000\n",
            "6/6 [==============================] - 4s 660ms/step - loss: 0.0735 - accuracy: 1.0000 - val_loss: 0.7925 - val_accuracy: 0.5000\n",
            "Epoch 55/1000\n",
            "6/6 [==============================] - 4s 551ms/step - loss: 0.0662 - accuracy: 1.0000 - val_loss: 0.8031 - val_accuracy: 0.4500\n",
            "Epoch 56/1000\n",
            "6/6 [==============================] - 3s 462ms/step - loss: 0.0551 - accuracy: 1.0000 - val_loss: 0.8231 - val_accuracy: 0.4000\n",
            "Epoch 57/1000\n",
            "6/6 [==============================] - 3s 476ms/step - loss: 0.0469 - accuracy: 1.0000 - val_loss: 0.8348 - val_accuracy: 0.4500\n",
            "Epoch 58/1000\n",
            "6/6 [==============================] - 3s 527ms/step - loss: 0.0464 - accuracy: 1.0000 - val_loss: 0.8516 - val_accuracy: 0.4500\n",
            "Epoch 59/1000\n",
            "6/6 [==============================] - 4s 676ms/step - loss: 0.0382 - accuracy: 1.0000 - val_loss: 0.8801 - val_accuracy: 0.4000\n",
            "Epoch 60/1000\n",
            "6/6 [==============================] - 3s 504ms/step - loss: 0.0340 - accuracy: 1.0000 - val_loss: 0.8872 - val_accuracy: 0.4500\n",
            "Epoch 61/1000\n",
            "6/6 [==============================] - 3s 469ms/step - loss: 0.0273 - accuracy: 1.0000 - val_loss: 0.8929 - val_accuracy: 0.4500\n",
            "Epoch 62/1000\n",
            "6/6 [==============================] - 3s 462ms/step - loss: 0.0267 - accuracy: 1.0000 - val_loss: 0.9071 - val_accuracy: 0.4500\n",
            "Epoch 63/1000\n",
            "4/6 [===================>..........] - ETA: 1s - loss: 0.0269 - accuracy: 1.0000"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-81-7283c8bc2050>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m model.fit(train_input,\n\u001b[0m\u001b[1;32m     13\u001b[0m           \u001b[0mtrain_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qiKmNrU-qptg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "min so far val_loss=0.6400\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras. import Embedding, Conv1D, MaxPooling1D, LSTM, Dense, Add, Input,Concatenate\n",
        "from keras.layers import Input, Embedding, Conv1D, GlobalMaxPooling1D, Dense\n",
        "from keras.models import Model\n",
        "# Assuming you have loaded FastText embeddings into 'embedding_matrix'\n",
        "\n",
        "# Input layer\n",
        "input_layer = Input(shape=(max_sequence_length,))\n",
        "\n",
        "# Embedding layer\n",
        "embedding_layer = Embedding(input_dim=num_words,\n",
        "                            output_dim=embedding_dim,\n",
        "                            weights=[embedding_matrix],\n",
        "                            input_length=max_sequence_length,\n",
        "                            trainable=False)(input_layer)\n",
        "\n",
        "# Add a 1D convolutional layer\n",
        "conv_layer = Conv1D(filters=300, kernel_size=3, activation='relu')(embedding_layer)\n",
        "\n",
        "\n",
        "max_pooling_layer = MaxPooling1D(pool_size=2)(conv_layer)\n",
        "# Second 1D convolutional layer\n",
        "conv_layer_2 = Conv1D(filters=300, kernel_size=3, activation='relu')(max_pooling_layer)\n",
        "# Apply global max pooling\n",
        "pooling_layer = GlobalMaxPooling1D()(conv_layer_2)\n",
        "\n",
        "# Add a dense layer\n",
        "dense_layer = Dense(50, activation='relu')(pooling_layer)\n",
        "\n",
        "# Output layer\n",
        "output_layer = Dense(1, activation='sigmoid')(dense_layer)\n",
        "\n",
        "\n",
        "# Create the model\n",
        "\n"
      ],
      "metadata": {
        "id": "K2RoIeZ985VB"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PUnJB1RM9AKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "val loss 6300"
      ],
      "metadata": {
        "id": "TMHTzq_NMo0W"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BtaK6kSVMq4V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}